---
doc_type: story
title: "WISH-2124: Redis infrastructure setup and migration from in-memory cache"
story_id: WISH-2124
story_prefix: WISH
status: ready-for-qa
follow_up_from: WISH-2009
phase: 2
created_at: "2026-01-28T00:00:00-07:00"
updated_at: "2026-01-30T09:00:00Z"
depends_on: [WISH-2009]
estimated_points: 4
sizing_warning: false
priority: P1
complexity: Medium
---

# WISH-2124: Redis infrastructure setup and migration from in-memory cache

## Follow-up Context

**Parent Story**: WISH-2009
**Source**: QA Elaboration Enhancement Opportunity #1
**Original Finding**: Redis infrastructure setup and migration from in-memory cache
**Category**: Infrastructure
**Impact**: High (production scaling)
**Effort**: Medium (new infrastructure)

### Background

WISH-2009 AC 17 uses in-memory cache (Map with TTL) for MVP feature flag storage. The adapter pattern ensures minimal code changes when migrating to Redis for distributed caching in production environments.

When production scaling requires distributed caching across multiple Lambda instances or API servers, this story migrates from in-memory cache to Redis infrastructure.

## Context

WISH-2009 implemented feature flag infrastructure with an in-memory Map cache adapter (AC 17) for MVP simplicity. While sufficient for single-instance development and low-traffic scenarios, in-memory caching has critical limitations for production distributed systems:

1. **No cross-Lambda sharing**: Each Lambda instance maintains separate cache, leading to inconsistent flag states across instances
2. **Cold start cache loss**: Every cold start requires database reads to repopulate cache, increasing latency
3. **Horizontal scaling inefficiency**: As traffic grows and Lambda scales, cache hit rate degrades (each instance warms independently)

The adapter pattern in WISH-2009 was designed with this migration in mind, providing a clean interface (`CacheAdapter`) that isolates cache implementation from business logic. This story migrates to Redis (via AWS ElastiCache or Docker Compose locally) for production-ready distributed caching.

**Key Dependencies:**
- WISH-2009 must be complete with working `CacheAdapter` interface
- Feature flag endpoints (`GET /api/config/flags/:flagKey`, `PATCH /api/admin/flags/:flagKey`) must be stable

**Production Readiness Signal:**
This story becomes critical when:
- Multiple Lambda instances run concurrently (horizontal scaling active)
- Cache hit rate < 50% due to cross-instance cache misses
- P95 response latency > 200ms due to frequent database reads

## Goal

Migrate feature flag caching from in-memory Map to Redis for distributed, production-ready caching. Enable consistent cache state across Lambda instances, improve cache hit rates at scale, and reduce database query load.

**Success Criteria:**
- Cache hit rate > 80% after warmup period (across all Lambda instances)
- P95 response time < 100ms for cached flag requests
- Zero production incidents during rollout (graceful fallback to database on Redis failure)
- Infrastructure cost remains predictable (~$15-30/month for MVP workload)

## Non-goals

- **Redis Cluster mode**: Single-instance ElastiCache is sufficient for MVP (<1000 flags). Cluster mode deferred to future scaling story.
- **Cache warming on deployment**: Pre-populating cache on cold start adds complexity. MVP relies on lazy population (cache-on-read).
- **Multi-region Redis replication**: Out of scope for MVP. Global latency optimization deferred to Phase 5+.
- **Cache analytics dashboard**: Monitoring via CloudWatch metrics is sufficient. Grafana/Prometheus dashboards deferred.
- **Redis persistence configuration**: Default persistence acceptable for MVP (flag data is in database)
- **Redis pub/sub for real-time flag updates**: Deferred to future story
- **Migration of other cache layers**: This story is feature flags only

## Scope

### Packages Affected

**Backend Infrastructure:**
- `apps/api/lego-api/domains/config/adapters/` - Replace `InMemoryCacheAdapter` with `RedisCacheAdapter`
- `apps/api/lego-api/core/cache/` - New Redis client singleton with connection pooling
- `apps/api/lego-api/domains/config/application/feature-flag-service.ts` - Wire Redis adapter via constructor injection
- `apps/api/lego-api/domains/config/index.ts` - DI container instantiation: `new RedisCacheAdapter(redisClient)`
- Infrastructure code (CDK/Terraform): ElastiCache cluster, VPC configuration, security groups

**Environment Configuration:**
- `.env` files: Add `REDIS_URL` environment variable
- AWS Secrets Manager: Store ElastiCache endpoint (production)
- Lambda environment variables: Inject `REDIS_URL` at runtime

**Docker Compose (Local Development):**
- `apps/api/lego-api/docker-compose.yml` - Add Redis 7.x service

### Endpoints Impacted

**No API contract changes** - this is a transparent infrastructure migration.

Existing endpoints continue to work unchanged:
- `GET /api/config/flags/:flagKey` - Now uses Redis cache (transparent to clients)
- `PATCH /api/admin/flags/:flagKey` - Invalidates Redis cache after update
- `GET /api/config/flags` - Now uses Redis cache for list operations

### Infrastructure Components

**AWS ElastiCache:**
- Instance type: `t3.micro` (1 GB memory)
- Engine: Redis 7.x
- VPC: Private subnets only (no public access)
- Security groups: Allow inbound port 6379 from Lambda security group
- Estimated cost: ~$15-30/month

**Lambda Configuration:**
- VPC attachment: Same VPC as ElastiCache
- Security group: Authorized to access ElastiCache on port 6379
- Memory: Increase by 128 MB for Redis client overhead
- Environment variable: `REDIS_URL=redis://<elasticache-endpoint>:6379`

**Local Development:**
- Docker Compose Redis service (image: `redis:7.2-alpine`)
- Port mapping: `6379:6379`
- Volume: Persist to `./data/redis` for debugging

## Acceptance Criteria

### AC 1: Redis Client Library Integration
**Given** the need for Redis connectivity in Lambda
**When** implementing the Redis adapter
**Then** use `ioredis` v5.x as the Redis client library
**And** configure connection pooling (max 10 connections per Lambda instance)
**And** enable automatic reconnection on connection failure
**And** set connection timeout to 2 seconds max

**Evidence:**
- `package.json` includes `ioredis` v5.x dependency
- Redis client singleton in `apps/api/lego-api/core/cache/redis-client.ts`
- Unit tests verify connection pool configuration

### AC 2: RedisCacheAdapter Implementation
**Given** the `CacheAdapter` interface from WISH-2009
**When** implementing `RedisCacheAdapter`
**Then** implement `get(key: string): Promise<string | null>` to retrieve cached values
**And** implement `set(key, value, ttlSeconds)` to store values with 5-minute TTL
**And** implement `delete(key)` to invalidate cache entries
**And** use cache key naming convention from WISH-2009: `feature_flags:{environment}:{flagKey}` (e.g., `feature_flags:production:wishlist-feature`)

**Evidence:**
- `RedisCacheAdapter.ts` in `apps/api/lego-api/domains/config/adapters/`
- Unit tests verify get/set/delete operations
- Integration tests with Docker Redis
- Cache key pattern matches WISH-2009 specification (AC 15)

### AC 3: Graceful Error Handling
**Given** Redis operations may fail (network issues, Redis unavailable)
**When** any Redis operation encounters an error
**Then** log the error with structured logging (`@repo/logger`)
**And** return gracefully without throwing exceptions
**And** for `get()`: return `null` to trigger database fallback
**And** for `set()` / `delete()`: fail silently (non-blocking cache write)

**Evidence:**
- Unit tests mock Redis errors, verify graceful handling
- CloudWatch logs show structured error messages (not uncaught exceptions)
- No 500 errors on Redis failures

### AC 4: Database Fallback on Cache Miss/Failure
**Given** Redis cache miss or connection failure
**When** flag service attempts to retrieve a flag
**Then** fall back to direct database read
**And** populate Redis cache after database read (if Redis available)
**And** respond with 200 status (success despite cache failure)

**Evidence:**
- Integration test: Stop Redis, request flag, verify database fallback
- CloudWatch logs: "cache_miss=true" or "cache_unavailable=true"
- Response time higher (~100-200ms) but request succeeds

### AC 5: Lambda Cold Start Redis Connection
**Given** a Lambda cold start with no active Redis connection
**When** the first request triggers Lambda initialization
**Then** establish Redis connection within 500ms
**And** if connection fails, log error and fall back to database
**And** respond with 200 status (no 500 errors on connection failure)

**Evidence:**
- CloudWatch logs: "Redis connected" or "Redis connection failed, using fallback"
- Cold start latency < 700ms (500ms Lambda init + 200ms request)
- Load test: Trigger 10 concurrent cold starts, all succeed

### AC 6: ElastiCache Failover Resilience
**Given** ElastiCache automatic failover in progress
**When** a request attempts to access Redis during failover window
**Then** retry Redis connection (3 attempts, 100ms exponential backoff)
**And** if failover completes within retry window, use cache successfully
**And** if failover exceeds retry window, fall back to database
**And** respond with 200 status (no client-facing errors)

**Evidence:**
- Integration test: Simulate Redis unavailability, verify retry + fallback
- CloudWatch logs: "Redis retry attempt X/3"
- No 500 errors during failover simulation

### AC 7: Cache TTL Configuration
**Given** cached flag values in Redis
**When** a flag is cached via `set(key, value, ttlSeconds)`
**Then** set TTL to 300 seconds (5 minutes) matching WISH-2009 spec
**And** Redis automatically expires keys after 5 minutes
**And** next request after expiration triggers cache miss → database read → re-cache

**Evidence:**
- Redis TTL command shows ~300 seconds for cached flags
- Integration test: Wait 5+ minutes, verify cache expired
- CloudWatch logs: "cache_expired=true" after TTL

### AC 8: Cache Invalidation on Flag Update
**Given** an admin updates a feature flag via `PATCH /api/admin/flags/:flagKey`
**When** the database update succeeds
**Then** immediately invalidate the Redis cache entry (`DELETE flag:<flagKey>`)
**And** cache invalidation occurs AFTER database commit (atomic consistency)
**And** next GET request triggers cache miss → database read → re-cache with updated value

**Evidence:**
- Integration test: Update flag → verify Redis DEL executed → GET flag → verify fresh value
- Unit test: Mock Redis DEL failure, verify error handling
- CloudWatch logs: "cache_invalidated=true" after PATCH

### AC 9: VPC Security Group Configuration
**Given** Lambda and ElastiCache deployed in AWS VPC
**When** infrastructure is provisioned
**Then** Lambda security group is authorized to access ElastiCache security group on port 6379
**And** ElastiCache is in private subnets only (no public access)
**And** VPC Flow Logs enabled for connectivity debugging

**Evidence:**
- CDK/Terraform synthesizes correct security group rules
- AWS CLI: `describe-security-groups` shows inbound rule for port 6379
- Pre-deployment test: Lambda healthcheck successfully pings Redis

### AC 10: Connection Pool Load Testing
**Given** concurrent Lambda invocations accessing Redis
**When** 50 parallel requests hit the API
**Then** Redis connection pool handles concurrency (max 10 connections)
**And** all 50 requests succeed with 200 status
**And** average response time < 50ms
**And** no "connection pool exhausted" errors

**Evidence:**
- Load test: Artillery/k6 with 50 concurrent requests
- CloudWatch metrics: `active_connections` <= 10
- No error logs related to connection pool exhaustion

### AC 11: Local Development Docker Compose Setup
**Given** developers need to test Redis integration locally
**When** running the API server in development mode
**Then** Docker Compose starts Redis 7.x container (`redis:7.2-alpine`)
**And** Redis accessible at `redis://localhost:6379`
**And** environment variable `REDIS_URL=redis://localhost:6379` in `.env.local`
**And** README updated with setup instructions

**Evidence:**
- `docker-compose.yml` includes Redis service definition
- `docker-compose up redis` starts Redis successfully
- Local integration tests pass against Docker Redis

### AC 12: Infrastructure Cost Monitoring
**Given** ElastiCache incurs monthly costs (~$15-30/month)
**When** the cluster is running in production
**Then** CloudWatch billing alarm triggers at $50/month threshold
**And** Cost Explorer tagged for Redis infrastructure (`Service=ElastiCache`, `Feature=FeatureFlags`)
**And** Monthly cost review process documented

**Evidence:**
- CloudWatch billing alarm configured
- Cost Explorer shows ElastiCache line item
- Documentation: `docs/infrastructure/cost-monitoring.md`

### AC 13: Canary Deployment Strategy
**Given** migrating from in-memory cache to Redis is a critical change
**When** deploying to production
**Then** use canary deployment: 5% traffic for 1 hour
**And** monitor error rate (<0.1%), cache hit rate (>80%), P95 latency (<100ms)
**And** if metrics pass, promote to 100% traffic
**And** if any metric fails, rollback to in-memory cache

**Evidence:**
- Deployment pipeline includes canary stage
- CloudWatch dashboard shows real-time metrics during canary
- Rollback plan documented and tested in staging

### AC 14: Service Layer Wiring with RedisCacheAdapter
**Given** the need to migrate from InMemoryCacheAdapter to RedisCacheAdapter
**When** setting up the feature flag service
**Then** update `apps/api/lego-api/domains/config/application/feature-flag-service.ts` to inject RedisCacheAdapter via constructor
**And** update DI container in `apps/api/lego-api/domains/config/index.ts` to instantiate RedisCacheAdapter with Redis client singleton
**And** remove InMemoryCacheAdapter once Redis proven stable

**Evidence:**
- `feature-flag-service.ts` constructor receives `cache: CacheAdapter` parameter
- DI container instantiates: `const cacheAdapter = new RedisCacheAdapter(redisClient)` then `new FlagService(flagRepository, cacheAdapter)`
- Unit tests verify constructor dependency injection
- Integration tests validate service uses Redis adapter for caching

### AC 15: Cache Key Pattern Compatibility with WISH-2009
**Given** WISH-2009's cache key pattern specification
**When** implementing RedisCacheAdapter key naming
**Then** use WISH-2009's pattern `feature_flags:{environment}:{flagKey}` for full compatibility
**And** maintain consistency with existing cache invalidation logic
**And** enable cache key filtering by environment and flag

**Evidence:**
- AC2 updated: Cache key pattern matches WISH-2009 (e.g., `feature_flags:production:wishlist-feature`)
- Integration tests verify pattern consistency across GET/SET/DELETE operations
- Cache invalidation tests confirm pattern works with existing PATCH logic
- Documentation updated showing pattern alignment

### AC 16: REDIS_URL Environment Variable Configuration
**Given** local and production environments needing Redis connectivity
**When** configuring environment variables
**Then** REDIS_URL must be set in `apps/api/lego-api/.env.local` for local development
**And** REDIS_URL injected via AWS Lambda environment variables for production
**And** support connection string format: `redis://[user][:password]@[host]:[port]/[db]`

**Evidence:**
- `.env.local` includes: `REDIS_URL=redis://localhost:6379` for Docker Compose
- Lambda function configuration includes `REDIS_URL` environment variable
- Production deployment sets REDIS_URL from AWS Secrets Manager
- Integration tests verify Redis client connects using REDIS_URL

## Reuse Plan

### Packages to Reuse
- **`packages/backend/db`**: Database client for fallback reads on cache miss/failure
- **`@repo/logger`**: Structured logging for Redis connection errors, cache hits/misses
- **`CacheAdapter` interface**: From WISH-2009, already defines contract for `get/set/delete`

### Patterns to Reuse
- **Port & Adapters pattern**: `CacheAdapter` interface isolates Redis implementation from business logic
- **Retry logic**: Similar to S3 client retry in `packages/backend/s3-client` (exponential backoff)
- **Environment configuration**: Same pattern as `DATABASE_URL` in `.env` files
- **DI container pattern**: Similar to how WISH-2009 wires CacheAdapter in `apps/api/lego-api/domains/config/application/` layer
- **Hexagonal architecture**: Use `domains/config/` directory structure (application, adapters, routes, types)

### Testing Patterns to Reuse
- **Docker Compose integration tests**: Similar to database setup (ephemeral container per test run)
- **MSW for API mocking**: Not needed for infrastructure change, but validates endpoint behavior unchanged

## Architecture Notes

### Hexagonal Architecture (Ports & Adapters)

**Port (Interface):**
```typescript
// From WISH-2009 - unchanged
interface CacheAdapter {
  get(key: string): Promise<string | null>
  set(key: string, value: string, ttlSeconds: number): Promise<void>
  delete(key: string): Promise<void>
}
```

**Adapter (Implementation):**
```typescript
// New Redis adapter
export class RedisCacheAdapter implements CacheAdapter {
  constructor(private redis: Redis) {}

  async get(key: string): Promise<string | null> {
    try {
      return await this.redis.get(`flag:${key}`)
    } catch (error) {
      logger.error('Redis GET failed', { key, error })
      return null // Triggers database fallback in service layer
    }
  }

  async set(key: string, value: string, ttlSeconds: number): Promise<void> {
    try {
      await this.redis.setex(`flag:${key}`, ttlSeconds, value)
    } catch (error) {
      logger.error('Redis SET failed', { key, error })
      // Non-blocking: Cache write failure doesn't fail request
    }
  }

  async delete(key: string): Promise<void> {
    try {
      await this.redis.del(`flag:${key}`)
    } catch (error) {
      logger.error('Redis DELETE failed', { key, error })
      // Non-blocking: Stale cache expires via TTL
    }
  }
}
```

**Service Layer (Unchanged from WISH-2009):**
```typescript
async getFlag(flagKey: string): Promise<Flag | null> {
  // Try cache first
  const cached = await this.cache.get(flagKey)
  if (cached) {
    return JSON.parse(cached)
  }

  // Cache miss/unavailable → database fallback
  const flag = await this.repository.findByKey(flagKey)
  if (!flag) return null

  // Populate cache (non-blocking)
  await this.cache.set(flagKey, JSON.stringify(flag), 300)

  return flag
}
```

**Dependency Injection:**
```typescript
// In DI container setup
const redisClient = createRedisClient(process.env.REDIS_URL!)
const cacheAdapter = new RedisCacheAdapter(redisClient)
const flagService = new FlagService(flagRepository, cacheAdapter)
```

**Separation of Concerns:**
- **Domain logic** (FlagService): Knows nothing about Redis, only uses `CacheAdapter` interface
- **Infrastructure** (RedisCacheAdapter): Handles Redis connection, error handling, retries
- **Configuration** (DI container): Wires concrete adapter based on environment

### Redis Client Singleton

Create reusable Redis client for other domains:
```typescript
// apps/api/lego-api/core/cache/redis.ts
import Redis from 'ioredis'

export const createRedisClient = (url: string): Redis => {
  return new Redis(url, {
    maxRetriesPerRequest: 3,
    retryStrategy(times) {
      const delay = Math.min(times * 100, 2000) // 100ms → 200ms → 400ms → max 2s
      return delay
    },
    enableReadyCheck: true,
    lazyConnect: false, // Connect eagerly on Lambda cold start
  })
}
```

## Infrastructure Notes

### AWS ElastiCache Configuration

**Instance Specification:**
- **Type**: `cache.t3.micro`
- **Engine**: Redis 7.2
- **Memory**: 1 GB
- **Availability Zone**: Single-AZ (Multi-AZ deferred to future HA story)
- **Estimated Cost**: $15-30/month (region-dependent)

**Network Configuration:**
- **VPC**: Private subnets only (no internet gateway)
- **Security Group**: Allow inbound TCP 6379 from Lambda security group
- **Endpoint**: Internal DNS name (e.g., `my-elasticache.abc123.0001.use1.cache.amazonaws.com:6379`)

**Lambda VPC Attachment:**
- **Subnets**: Private subnets with NAT gateway for outbound traffic (if needed)
- **Security Group**: Authorized to access ElastiCache security group
- **IAM Policy**: `ec2:CreateNetworkInterface`, `ec2:DescribeNetworkInterfaces`, `ec2:DeleteNetworkInterface`

### Local Development Setup

**Docker Compose Service:**
```yaml
services:
  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --appendonly yes
```

**Environment Configuration:**
```bash
# .env.local
REDIS_URL=redis://localhost:6379
```

**Developer Onboarding:**
1. Run `docker-compose up redis` to start Redis locally
2. Run `pnpm dev` to start API server (automatically connects to Redis)
3. Run `pnpm test` for integration tests (uses Docker Redis)

### Monitoring and Observability

**CloudWatch Metrics:**
- `cache_hit_rate`: Percentage of requests served from cache (target: >80%)
- `redis_connection_errors`: Count of connection failures (alert threshold: >5/minute)
- `response_latency_p95`: 95th percentile response time (target: <100ms for cache hits)
- `active_connections`: Current Redis connections (alert threshold: >8 sustained)

**CloudWatch Logs:**
- Structured logs with fields: `cache_hit`, `cache_miss`, `cache_unavailable`, `error.type`
- Example query: `fields @timestamp, cache_hit | filter domain = "config" | stats avg(cache_hit) as hit_rate`

**Cost Monitoring:**
- Billing alarm at $50/month threshold
- Cost Explorer tag: `Service=ElastiCache`, `Feature=FeatureFlags`
- Monthly review: Right-size instance based on memory usage and flag count

## Test Plan

See `_pm/TEST-PLAN.md` for comprehensive test plan including:
- Happy path tests (5 tests)
- Error cases (4 tests)
- Edge cases (5 tests)
- Backend testing requirements (.http files, CloudWatch queries)
- Success criteria and rollback plan

## UI/UX Notes

See `_pm/UIUX-NOTES.md` - **SKIPPED** (no UI changes in this infrastructure story)

## Dev Feasibility Review

See `_pm/DEV-FEASIBILITY.md` for detailed feasibility analysis including:
- MVP-critical risks (5 risks identified)
- Missing requirements (4 decisions needed)
- Change surface analysis
- MVP evidence expectations
- Confidence: Medium-High

## Risks & Mitigations

### Risk 1: Lambda Cold Start Redis Connection Failures
**Likelihood**: Medium
**Impact**: High (blocks flag retrieval if fallback fails)

**Mitigation:**
- Retry logic: 3 attempts with 100ms exponential backoff
- Database fallback on connection failure
- Connection timeout: 2 seconds max (within APIGW 29s timeout)
- Integration tests validate fallback under connection failure

### Risk 2: VPC Security Group Misconfiguration
**Likelihood**: Medium
**Impact**: High (blocks all Redis access)

**Mitigation:**
- Infrastructure-as-code validation (CDK/Terraform synthesize checks)
- Pre-deployment connectivity test (Lambda healthcheck pings Redis)
- VPC Flow Logs enabled for debugging
- Step-by-step security group configuration documented

### Risk 3: Cache Invalidation Race Condition
**Likelihood**: Low
**Impact**: Medium (clients receive stale cached values)

**Mitigation:**
- Cache invalidation in same transaction (DELETE after database commit)
- Integration tests verify invalidation atomicity
- TTL ensures stale cache expires within 5 minutes (worst case)

### Risk 4: Infrastructure Cost Overruns
**Likelihood**: Low
**Impact**: Medium (unexpected AWS bills)

**Mitigation:**
- CloudWatch billing alarm at $50/month threshold
- Cost Explorer tagging for ElastiCache
- Monthly cost review and right-sizing process
- Start with t3.micro (cheapest instance), scale up only if needed

### Risk 5: Connection Pool Exhaustion Under Load
**Likelihood**: Low
**Impact**: Medium (request queuing, increased latency)

**Mitigation:**
- Configure max connection pool: 10 connections per Lambda instance
- Load test with 50 concurrent requests before production
- CloudWatch metrics for active connections (alert if >8 sustained)
- Horizontal Lambda scaling handles overflow (new instances = new connection pools)

## Deployment Strategy

### Phase 1: Local Development Setup (Week 1)
1. Add `ioredis` dependency to `package.json`
2. Create Docker Compose Redis service
3. Implement `RedisCacheAdapter` with unit tests
4. Update `.env.local` with `REDIS_URL`
5. Run integration tests against Docker Redis

### Phase 2: Staging Deployment (Week 1-2)
1. Provision ElastiCache t3.micro in staging VPC
2. Configure security groups (Lambda → ElastiCache)
3. Deploy Lambda with Redis adapter to staging
4. Run integration tests against staging ElastiCache
5. Manual smoke tests via `.http` files

### Phase 3: Production Canary (Week 2)
1. Deploy to 5% of production traffic
2. Monitor for 1 hour:
   - Error rate, cache hit rate, latency, connection errors
3. If metrics pass → promote to 25% → 50% → 100%
4. If any metric fails → rollback to in-memory cache

### Phase 4: Post-Deployment Validation (Week 2-3)
1. Monitor CloudWatch metrics for 48 hours
2. Verify Cost Explorer shows expected ElastiCache charges
3. Customer-reported issues: Zero tolerance (rollback if >1 incident)
4. Document lessons learned and update runbooks

## Related Stories

**Dependencies:**
- **WISH-2009**: Feature flag infrastructure (provides `CacheAdapter` interface)

**Follow-ups:**
- **WISH-2016**: Admin UI for feature flag management (consumes Redis-backed flags)
- **WISH-2119**: Flag scheduling (auto-enable/disable at scheduled times)
- **WISH-2039**: User-level targeting for feature flags (extends cache key patterns)

**Future Enhancements:**
- Redis Cluster mode for high availability (multi-AZ failover)
- Cache warming on deployment (pre-populate common flags)
- Multi-region Redis replication (global latency optimization)

## Definition of Done

- [ ] All 13 acceptance criteria pass
- [ ] Unit tests pass (20+ tests, >80% coverage)
- [ ] Integration tests pass (15+ tests with Docker Redis)
- [ ] Load tests pass (50 concurrent requests, no errors)
- [ ] Infrastructure tests pass (CDK/Terraform synthesize validates)
- [ ] Manual validation complete (Redis CLI, AWS CLI, Lambda logs)
- [ ] Production canary successful (1 hour at 5% traffic, all metrics green)
- [ ] Documentation updated (README, cost monitoring guide, architecture docs)
- [ ] CloudWatch dashboard shows healthy cache metrics
- [ ] Cost Explorer confirms ElastiCache charges ~$15-30/month
- [ ] No customer-reported issues for 48 hours post-deployment
- [ ] TypeScript compilation passes
- [ ] ESLint passes with no errors
- [ ] Code review approved

## Token Budget

### Phase Summary

| Phase | Estimated | Actual | Delta | Notes |
|-------|-----------|--------|-------|-------|
| Story Generation | ~15k | — | — | Leader + 3 workers |
| Elaboration | ~12k | — | — | Follow-up story from WISH-2009 |
| Implementation | ~15k | — | — | Infrastructure + Migration + Testing |
| Code Review | ~6k | — | — | Infrastructure changes |
| **Total** | ~48k | — | — | Medium-sized infrastructure story |

## Agent Log

| Timestamp (America/Denver) | Agent | Action | Outputs |
|---|---|---|---|
| 2026-01-28 00:00 | pm-story-followup-leader | Created follow-up from WISH-2009 finding #2 | WISH-2124.md (initial draft) |
| 2026-01-28 15:30 | pm-story-generation-leader | Generated complete story | WISH-2124.md (final), TEST-PLAN.md, UIUX-NOTES.md, DEV-FEASIBILITY.md |
| 2026-01-29 17:45 | elab-completion-leader | Elaboration report and fixes | ELAB-WISH-2124.md, story updated with AC 14-16 |
| 2026-01-30 09:00 | elab-completion-leader | QA Discovery Notes and status update | Story moved to ready-to-work |

---

## QA Discovery Notes (for PM Review)

_Added by QA Elaboration on 2026-01-30_

### Gaps Identified

| # | Finding | User Decision | Notes |
|---|---------|---------------|-------|
| 1 | Cache interface incompatibility with WISH-2009 | **Add as AC17** | Implement `RedisCacheAdapter` conforming to existing `FeatureFlagCache` interface from `domains/config/ports/index.ts`. Use Redis hash structure `feature_flags:{environment}` with HSET/HGETALL for atomic cache semantics matching WISH-2009's design. This resolves interface compatibility between proposed simple key-value adapter and WISH-2009's environment-scoped caching model. |
| 2 | Redis data structure undefined | **Add as AC17 (detail)** | Specify Redis hash structure per environment: `feature_flags:{environment}` with HSET per flag, HGETALL for bulk retrieval, DEL for invalidation. Preserves atomic environment cache model while enabling distributed caching across Lambda instances. Commands: `HSET feature_flags:production {flagKey} {JSON.stringify(flag)}`, `HGETALL feature_flags:production`, `DEL feature_flags:production`. |

### Enhancement Opportunities

| # | Finding | User Decision | Notes |
|---|---------|---------------|-------|
| 1 | Redis Cluster mode for high availability | Not Reviewed | Deferred to future scaling story. Single-instance ElastiCache sufficient for MVP. |
| 2 | Cache warming on deployment | Not Reviewed | Pre-populating cache on cold start adds complexity. MVP relies on lazy population (cache-on-read). |
| 3 | Multi-region Redis replication | Not Reviewed | Out of scope for MVP. Global latency optimization deferred to Phase 5+. |
| 4 | Cache analytics dashboard | Not Reviewed | CloudWatch metrics sufficient for MVP. Grafana/Prometheus dashboards deferred. |
| 5 | Redis persistence configuration | Not Reviewed | Default persistence acceptable for MVP (flag data is in database). |
| 6 | Redis pub/sub for real-time flag updates | Not Reviewed | Deferred to future story. |
| 7 | Migration of other cache layers | Not Reviewed | This story is feature flags only. Other domains reuse redis-client singleton in future stories. |
| 8 | Cost optimization via reserved capacity | Not Reviewed | Pay-as-you-go sufficient for MVP. Reserved capacity planning deferred. |
| 9 | Active-active failover strategy | Not Reviewed | Single-AZ sufficient for MVP. Multi-AZ HA deferred to future story. |
| 10 | Cache key namespace collision prevention | Not Reviewed | Current naming convention (`feature_flags:{environment}:{flagKey}` pattern) prevents collisions. Documented in AC15 and AC17. |

### Follow-up Stories Suggested

- [x] WISH-2125: Redis Cluster mode for high availability (multi-AZ failover, load balancing) → WISH-20320
- [x] WISH-2126: Cache warming strategy (pre-populate on cold start, CloudWatch triggers) → WISH-20330
- [x] WISH-2127: Multi-region Redis replication (global latency optimization) → WISH-20340
- [x] WISH-2128: Cache analytics dashboard (Grafana/Prometheus integration) → WISH-20350

### Items Marked Out-of-Scope

- Redis Cluster mode: Single-instance ElastiCache sufficient for MVP (<1000 flags). Cluster mode deferred to future scaling story.
- Cache warming on deployment: Pre-populating cache on cold start adds complexity. MVP relies on lazy population (cache-on-read).
- Multi-region Redis replication: Out of scope for MVP. Global latency optimization deferred to Phase 5+.
- Cache analytics dashboard: Monitoring via CloudWatch metrics is sufficient. Grafana/Prometheus dashboards deferred.
- Redis persistence configuration: Default persistence acceptable for MVP (flag data is in database).
- Redis pub/sub for real-time flag updates: Deferred to future story.
- Migration of other cache layers: This story is feature flags only.
