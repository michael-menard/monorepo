---
status: backlog
follow_up_from: WISH-2013
created: 2026-01-28
story_id: WISH-2123
title: Content Moderation - AI/ML Image Scanning
epic: Wishlist Feature
phase: 4 - Security Enhancements
priority: P2
depends_on: [WISH-2013]
complexity: Large
effort: 5-8 points
---

# WISH-2123: Content Moderation - AI/ML Image Scanning

## Follow-up Context

**Parent Story:** WISH-2013 (File Upload Security Hardening)

**Source:** QA Discovery Notes - Follow-up Stories Suggested

**Original Finding:** "Content Moderation - AI/ML-based scanning for inappropriate/offensive images"

**Category:** Enhancement Opportunity

**Impact:** Medium (Trust & Safety requirement for production platform)

**Effort:** High (AI/ML pipeline integration, moderation workflow, review tooling)

---

## Context

While WISH-2013 addresses security threats (viruses, malware, unauthorized access), it does not prevent users from uploading inappropriate, offensive, or adult content to the wishlist feature. As the platform grows and user-generated content increases, content moderation becomes critical for:

1. **Trust & Safety:** Protecting users from exposure to harmful or offensive imagery
2. **Community Standards:** Enforcing community guidelines and acceptable use policies
3. **Legal Compliance:** Meeting regulatory requirements for user-generated content platforms
4. **Brand Protection:** Preventing platform misuse that could damage reputation

### Background

**Current State (After WISH-2013):**
- Virus scanning prevents malicious files
- File type validation limits uploads to images only
- No content moderation or inappropriate content detection
- No mechanism to flag or remove offensive images
- No admin tooling for content review

**Content Risks Without This Story:**
- Users could upload sexually explicit imagery
- Users could upload violent or graphic content
- Users could upload hate symbols or offensive imagery
- No automated detection or prevention mechanism
- Manual reporting only, requiring reactive moderation

**User-Generated Content Challenges:**
- LEGO platform attracts diverse user base including minors
- Wishlist images are potentially shareable or public-facing
- Manual moderation does not scale with user growth
- Automated moderation reduces exposure and response time

---

## Goal

Implement AI/ML-based content moderation to automatically detect and flag inappropriate, offensive, or adult content in uploaded wishlist images. Provide admin tooling for content review, user notification, and policy enforcement.

---

## Non-goals

- **Video Content Moderation:** Only image moderation in scope (no video uploads in wishlist)
- **Text Content Moderation:** Comments, descriptions, or user-generated text out of scope
- **Real-Time Chat Moderation:** Not applicable to wishlist feature
- **User Reporting Mechanism:** Manual user reporting deferred to separate community safety story
- **Appeal Process:** User appeals for moderation decisions deferred to Phase 2
- **Multi-Language Content Detection:** Text-based moderation not in scope

---

## Scope

### Packages Affected

- `apps/api/lego-api/domains/wishlist/` - Integrate moderation into upload flow
- `apps/api/lego-api/core/moderation/` - AI/ML moderation service (new)
- `apps/api/lego-api/domains/admin/` - Admin moderation review endpoints (new)
- `apps/web/admin-dashboard/` - Admin moderation review UI (new or extend existing)
- `packages/backend/database-schema/` - Moderation results table, audit log
- `packages/core/api-client/src/schemas/` - Moderation result schemas

### Endpoints/Surfaces

**Backend Endpoints (New):**
- `GET /api/admin/moderation/queue` - Get pending moderation items
- `POST /api/admin/moderation/:id/approve` - Approve flagged content
- `POST /api/admin/moderation/:id/reject` - Reject and remove flagged content
- `GET /api/admin/moderation/stats` - Moderation metrics and trends

**Frontend Surfaces:**
- Admin moderation queue page (table view)
- Image preview with moderation labels and confidence scores
- Approve/Reject action buttons
- Moderation history and audit log

### Files to Create

1. **Moderation Service:**
   - `apps/api/lego-api/core/moderation/content-scanner.ts` - AI/ML integration adapter
   - `apps/api/lego-api/core/moderation/__tests__/content-scanner.test.ts` - Unit tests
   - `apps/api/lego-api/core/moderation/types.ts` - Moderation result types

2. **Admin Domain:**
   - `apps/api/lego-api/domains/admin/application/moderation-service.ts` - Moderation review logic
   - `apps/api/lego-api/domains/admin/adapters/moderation-repository.ts` - Database access
   - `apps/api/lego-api/domains/admin/routes.ts` - Admin moderation endpoints
   - `apps/api/lego-api/domains/admin/__tests__/moderation.test.ts` - Integration tests

3. **Database Schema:**
   - `packages/backend/database-schema/src/schema/moderation.ts` - Moderation results table
   - `packages/backend/database-schema/src/migrations/` - Migration for new table

4. **Frontend Admin UI:**
   - `apps/web/admin-dashboard/src/pages/ModerationQueue.tsx` - Moderation queue page
   - `apps/web/admin-dashboard/src/components/ModerationCard/` - Moderation review card
   - `apps/web/admin-dashboard/src/components/ModerationCard/__tests__/` - Component tests

### Files to Modify

1. **Wishlist Upload Flow:**
   - `apps/api/lego-api/domains/wishlist/application/wishlist-service.ts` - Add moderation scan after upload
   - `apps/api/lego-api/domains/wishlist/adapters/wishlist-repository.ts` - Store moderation status

2. **Database Schema:**
   - `packages/backend/database-schema/src/schema/index.ts` - Add moderation_status to wishlist_items

---

## Acceptance Criteria

### AC1: AI/ML Content Moderation Integration
**Given** a wishlist image has been successfully uploaded to S3
**When** the upload completes and backend registers the file
**Then** the content moderation service scans the image for inappropriate content
**And** moderation results include labels (e.g., 'explicit-nudity', 'suggestive', 'violence', 'hate-symbols')
**And** moderation results include confidence scores (0-100%) for each label

### AC2: Automatic Flagging Based on Thresholds
**Given** moderation scan completes with results
**When** any label exceeds high-confidence threshold (e.g., ≥ 90% for explicit content)
**Then** the image is automatically flagged as 'pending-review'
**And** the image is not visible in user's wishlist until review completes
**And** audit log records automatic flagging decision

### AC3: Manual Review Queue for Flagged Content
**Given** images have been flagged for review
**When** an admin navigates to `/admin/moderation/queue`
**Then** the page displays all pending moderation items in a table
**And** each row shows image thumbnail, moderation labels, confidence scores, user ID, upload timestamp
**And** table is sortable by confidence score and upload date
**And** pagination is supported (25 items per page)

### AC4: Image Preview with Moderation Labels
**Given** an admin views a moderation queue item
**When** the admin clicks on the image thumbnail
**Then** a modal displays full-size image preview
**And** modal shows all moderation labels with confidence scores
**And** modal shows user information (userId, upload date)
**And** modal shows Approve and Reject action buttons

### AC5: Approve Flagged Content
**Given** an admin reviews a flagged image
**When** the admin clicks "Approve" button
**Then** the image moderation status is updated to 'approved'
**And** the image becomes visible in the user's wishlist
**And** audit log records admin approval decision with admin userId and timestamp
**And** image is removed from moderation queue

### AC6: Reject Flagged Content
**Given** an admin reviews a flagged image
**When** the admin clicks "Reject" button
**Then** the image moderation status is updated to 'rejected'
**And** the image is permanently deleted from S3
**And** the wishlist item's image reference is removed
**And** user is notified via email/notification (notification mechanism out of scope for MVP)
**And** audit log records admin rejection decision with reason and timestamp

### AC7: Moderation Status Stored in Database
**Given** moderation scan completes
**When** moderation results are processed
**Then** moderation status is stored in `wishlist_items.moderation_status` column
**And** status values are: 'pending-scan', 'clean', 'pending-review', 'approved', 'rejected'
**And** moderation results (labels, scores) are stored in `moderation_results` table
**And** database schema enforces referential integrity

### AC8: Moderation Metrics and Stats
**Given** moderation events have occurred
**When** an admin navigates to `/admin/moderation/stats`
**Then** the page displays moderation metrics:
  - Total images scanned
  - Automatic flags (by category)
  - Admin approval rate
  - Admin rejection rate
  - Average review time
**And** metrics are filterable by date range (last 7 days, 30 days, all time)

### AC9: Moderation Service Adapter Pattern
**Given** moderation service is implemented
**When** the service scans content
**Then** the implementation uses adapter pattern to support multiple providers
**And** adapters are available for: AWS Rekognition (MVP), Google Cloud Vision (future), Azure Content Moderator (future)
**And** provider is configurable via environment variable `MODERATION_PROVIDER`

### AC10: Async Moderation Does Not Block Upload
**Given** a user uploads an image
**When** the image upload completes successfully
**Then** moderation scan runs asynchronously in background
**And** user sees upload success immediately
**And** image is initially marked as 'pending-scan'
**And** user experience is not blocked by moderation latency

### AC11: Low-Confidence Detections Auto-Approved
**Given** moderation scan detects potentially inappropriate content
**When** all labels have confidence scores below threshold (< 50%)
**Then** the image is automatically marked as 'clean'
**And** no manual review is required
**And** image is immediately visible in wishlist

### AC12: Medium-Confidence Detections Auto-Flagged
**Given** moderation scan detects potentially inappropriate content
**When** any label has confidence score between 50% and 89%
**Then** the image is flagged as 'pending-review'
**And** image is added to manual review queue
**And** audit log records threshold-based flagging

### AC13: Admin Authorization for Moderation Endpoints
**Given** moderation endpoints are implemented
**When** a non-admin user attempts to access `/api/admin/moderation/*`
**Then** the request is rejected with 403 Forbidden
**And** only users with 'admin' role can access moderation endpoints
**And** authorization middleware is consistent with WISH-2008 pattern

### AC14: Moderation Test Coverage with MSW Mocks
**Given** MSW handlers are extended for moderation
**When** integration tests run for content moderation
**Then** MSW mocks AI/ML moderation responses (clean, flagged, service error)
**And** tests verify auto-flagging behavior for high-confidence detections
**And** tests verify auto-approval for low-confidence detections
**And** tests verify manual review workflow (approve/reject)

### AC15: Documentation Updates
**Given** content moderation is implemented
**When** developers need to understand moderation flow
**Then** documentation includes:
  - Moderation pipeline architecture diagram
  - AI/ML provider integration guide
  - Confidence threshold rationale
  - Admin review workflow instructions
  - Testing guide for moderation scenarios

---

## Test Plan

*Comprehensive test coverage for content moderation pipeline and admin workflows.*

### Happy Path Tests:

1. **Clean Image Upload (Low Confidence):**
   - User uploads LEGO set image
   - Moderation scan returns all labels < 50% confidence
   - Image auto-approved as 'clean'
   - Image immediately visible in wishlist
   - No manual review required

2. **Flagged Image Upload (High Confidence):**
   - User uploads flagged content
   - Moderation scan returns 'explicit-nudity' at 95% confidence
   - Image auto-flagged as 'pending-review'
   - Image not visible in wishlist
   - Admin sees image in moderation queue

3. **Admin Approves Flagged Image (False Positive):**
   - Admin reviews flagged LEGO minifigure (false positive)
   - Admin clicks "Approve"
   - Image status updated to 'approved'
   - Image becomes visible in user's wishlist
   - Audit log records approval

4. **Admin Rejects Flagged Image (True Positive):**
   - Admin reviews flagged inappropriate content
   - Admin clicks "Reject"
   - Image deleted from S3
   - Wishlist item image reference removed
   - User notified (notification mechanism out of scope)
   - Audit log records rejection

### Error Cases:

1. **Moderation Service Unavailable:**
   - User uploads image
   - Moderation service returns error (500 or timeout)
   - Image marked as 'pending-review' (fail-safe)
   - Admin notified of scan failure
   - Manual review required

2. **Invalid Moderation Response:**
   - Moderation service returns malformed data
   - Service logs error and marks image as 'pending-review'
   - Alert triggered for operations team
   - No user-facing impact (async)

3. **Non-Admin Access to Moderation Queue:**
   - Regular user attempts to access `/admin/moderation/queue`
   - Request rejected with 403 Forbidden
   - Authorization middleware blocks access

4. **Concurrent Admin Reviews (Same Image):**
   - Two admins review same flagged image simultaneously
   - First admin approves, second admin attempts to reject
   - Optimistic locking prevents second action
   - Second admin sees "Item already reviewed" error

### Edge Cases:

1. **Image Uploaded Before Moderation Feature Deployed:**
   - Existing wishlist items have null `moderation_status`
   - Background job scans existing images (separate story)
   - Existing images default to 'clean' for MVP

2. **Moderation Scan Timeout:**
   - Scan takes > 30 seconds (timeout threshold)
   - Timeout logged as error
   - Image marked as 'pending-review' (fail-safe)

3. **Multiple High-Confidence Labels:**
   - Image flagged for 'explicit-nudity' (92%) and 'violence' (88%)
   - Both labels displayed in admin review UI
   - Admin makes single decision (approve or reject)

4. **Low-Confidence Detection After Auto-Approval:**
   - Image auto-approved with all labels < 50%
   - User later reports content (separate story)
   - Manual admin review can override auto-approval

### Required Evidence:

- 25+ unit tests for moderation service and adapters
- 20+ integration tests for admin moderation endpoints
- 15+ component tests for ModerationQueue and ModerationCard
- 5+ Playwright E2E tests for admin review workflow
- MSW mock handlers for AWS Rekognition responses
- Moderation metrics validated in staging environment

---

## Reuse Plan

### Reuse from WISH-2013 (File Upload Security)

1. **S3 Upload Flow:**
   - Moderation scan triggers after virus scan completes
   - Reuse async upload completion event handler
   - No changes to presigned URL flow

2. **Security Test Fixtures:**
   - Extend test fixtures with moderation test images
   - Reuse MSW handler patterns from WISH-2013

### Reuse from WISH-2008 (Authorization)

1. **Admin Authorization Middleware:**
   - Reuse admin role check for moderation endpoints
   - Consistent authorization pattern across admin surfaces

### Reusable Components for Future Stories

1. **Content Moderation Service:**
   - Adapter pattern supports other content types (PDFs, videos in future)
   - Reusable for MOC instructions, gallery, user profiles

2. **Admin Moderation UI:**
   - Moderation queue component reusable for text moderation
   - Approve/Reject workflow reusable for other admin tasks

3. **Moderation Test Infrastructure:**
   - MSW moderation handlers reusable for future content features
   - Test fixtures for flagged content scenarios

---

## Architecture Notes

### Hexagonal Architecture (Ports & Adapters)

**Ports (Interfaces):**

1. **Content Scanner Port:**
   ```typescript
   export interface ContentScanner {
     scanImage(s3Key: string): Promise<ModerationResult>
   }

   export type ModerationResult = {
     labels: ModerationLabel[]
     status: 'clean' | 'pending-review' | 'flagged'
   }

   export type ModerationLabel = {
     name: string
     category: 'explicit-nudity' | 'suggestive' | 'violence' | 'hate-symbols' | 'offensive-gestures'
     confidence: number // 0-100
   }
   ```

2. **Moderation Repository Port:**
   ```typescript
   export interface ModerationRepository {
     storeModerationResult(itemId: string, result: ModerationResult): Promise<void>
     updateModerationStatus(itemId: string, status: ModerationStatus): Promise<void>
     getPendingReviews(pagination: Pagination): Promise<ModerationQueueItem[]>
     recordAdminAction(action: AdminAction): Promise<void>
   }
   ```

**Adapters (Implementations):**

1. **AWS Rekognition Content Scanner Adapter (MVP):**
   - Integrates with AWS Rekognition DetectModerationLabels API
   - Implements `ContentScanner` port
   - Maps Rekognition labels to internal ModerationLabel format

2. **PostgreSQL Moderation Repository Adapter:**
   - Implements `ModerationRepository` port
   - Stores results in `moderation_results` table
   - Updates `wishlist_items.moderation_status` column

### Moderation Pipeline Flow

```
1. User uploads image (WISH-2002 flow)
   ↓
2. Virus scan completes (WISH-2013 flow)
   ↓ (if clean)
3. Content moderation scan triggered (async)
   ↓
4. AWS Rekognition DetectModerationLabels API call
   ↓
5. Moderation result with labels and confidence scores
   ↓
6. Evaluate confidence thresholds:
   - All labels < 50% → Auto-approve ('clean')
   - Any label 50-89% → Flag for review ('pending-review')
   - Any label ≥ 90% → Auto-flag ('flagged')
   ↓
7a. If auto-approved: Image visible in wishlist immediately
7b. If flagged: Image hidden, added to admin queue
   ↓ (if flagged)
8. Admin reviews in moderation queue
   ↓
9. Admin decision:
   - Approve → Image visible, audit log
   - Reject → Image deleted, user notified, audit log
```

### AI/ML Provider Options

**Option 1: AWS Rekognition (Recommended for MVP):**
- **Pros:** AWS-native integration, no data transfer costs, proven accuracy for explicit content
- **Cons:** Limited to AWS regions, per-image pricing (~$0.001/image)
- **Use Case:** MVP and production deployment on AWS infrastructure

**Option 2: Google Cloud Vision API:**
- **Pros:** High accuracy, multi-category detection, API-based (platform-agnostic)
- **Cons:** External API dependency, data transfer costs, per-request pricing (~$0.0015/image)
- **Use Case:** Alternative if AWS Rekognition accuracy insufficient

**Option 3: Azure Content Moderator:**
- **Pros:** Comprehensive moderation (image + text), custom training support
- **Cons:** Requires Azure account, higher pricing (~$0.002/image)
- **Use Case:** Enterprise deployments with Azure infrastructure

**MVP Recommendation:** AWS Rekognition for cost-effectiveness and AWS integration. Adapter pattern allows switching providers if needed.

---

## Infrastructure Notes

### Database Schema

**New Table: `moderation_results`**
```sql
CREATE TABLE moderation_results (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  wishlist_item_id UUID NOT NULL REFERENCES wishlist_items(id) ON DELETE CASCADE,
  scanned_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  provider VARCHAR(50) NOT NULL, -- 'aws-rekognition', 'google-vision', etc.
  labels JSONB NOT NULL, -- Array of {name, category, confidence}
  status VARCHAR(20) NOT NULL, -- 'clean', 'pending-review', 'flagged'
  reviewed_at TIMESTAMPTZ,
  reviewed_by UUID REFERENCES users(id),
  review_decision VARCHAR(20), -- 'approved', 'rejected'
  review_notes TEXT,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_moderation_wishlist_item ON moderation_results(wishlist_item_id);
CREATE INDEX idx_moderation_status ON moderation_results(status);
CREATE INDEX idx_moderation_reviewed_at ON moderation_results(reviewed_at);
```

**Modify Table: `wishlist_items`**
```sql
ALTER TABLE wishlist_items
ADD COLUMN moderation_status VARCHAR(20) DEFAULT 'pending-scan';
-- Values: 'pending-scan', 'clean', 'pending-review', 'approved', 'rejected'

CREATE INDEX idx_wishlist_moderation_status ON wishlist_items(moderation_status);
```

### AWS Rekognition Configuration

- **API:** `DetectModerationLabels`
- **Region:** us-east-1 (or match S3 bucket region)
- **IAM Policy:** Grant `rekognition:DetectModerationLabels` permission to Lambda role
- **Minimum Confidence:** 50% (configurable threshold)
- **Pricing:** ~$0.001 per image scanned

---

## HTTP Contract Plan

### New Admin Endpoints

#### Get Moderation Queue

**Endpoint:** `GET /api/admin/moderation/queue`

**Query Parameters:**
```
?status=pending-review&page=1&limit=25&sortBy=confidence&sortOrder=desc
```

**Response:**
```json
{
  "items": [
    {
      "id": "uuid",
      "wishlistItemId": "uuid",
      "userId": "uuid",
      "imageUrl": "https://s3.amazonaws.com/...",
      "labels": [
        {
          "name": "Explicit Nudity",
          "category": "explicit-nudity",
          "confidence": 92
        }
      ],
      "uploadedAt": "2026-01-28T12:00:00Z",
      "status": "pending-review"
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 25,
    "total": 47
  }
}
```

#### Approve Flagged Content

**Endpoint:** `POST /api/admin/moderation/:id/approve`

**Request:**
```json
{
  "notes": "False positive - LEGO minifigure"
}
```

**Response:**
```json
{
  "success": true,
  "moderationId": "uuid",
  "status": "approved",
  "reviewedAt": "2026-01-28T12:05:00Z"
}
```

#### Reject Flagged Content

**Endpoint:** `POST /api/admin/moderation/:id/reject`

**Request:**
```json
{
  "reason": "Inappropriate content - explicit imagery",
  "notifyUser": true
}
```

**Response:**
```json
{
  "success": true,
  "moderationId": "uuid",
  "status": "rejected",
  "imageDeleted": true,
  "reviewedAt": "2026-01-28T12:05:00Z"
}
```

#### Get Moderation Stats

**Endpoint:** `GET /api/admin/moderation/stats`

**Query Parameters:**
```
?dateRange=last-30-days
```

**Response:**
```json
{
  "totalScanned": 1247,
  "autoApproved": 1198,
  "flaggedForReview": 49,
  "adminApproved": 32,
  "adminRejected": 17,
  "averageReviewTimeMinutes": 8.5,
  "flagsByCategory": {
    "explicit-nudity": 15,
    "suggestive": 20,
    "violence": 8,
    "hate-symbols": 6
  }
}
```

---

## Seed Requirements

**Not applicable for MVP.** Moderation results generated by real scans.

**Test Seeds:**
- Test images for moderation scenarios (clean, flagged, edge cases)
- Mock moderation results for MSW handlers

---

## UI/UX Notes

### User-Facing Changes

1. **Upload Flow (No User-Facing Changes):**
   - Moderation is asynchronous and transparent to users
   - User sees upload success immediately
   - Image appears in wishlist if auto-approved
   - If flagged, image not visible until admin review

2. **Rejection Notification (Future):**
   - If admin rejects content, user notified via email/toast
   - Notification message: "Your uploaded image was removed due to policy violation"
   - Notification mechanism out of scope for MVP (manual notification)

### Admin UI

1. **Moderation Queue Page:**
   - Table layout with image thumbnails (100x100px)
   - Sortable columns: Confidence, Upload Date, User ID
   - Pagination controls (25 items per page)
   - Filters: Status (pending-review, flagged), Date range

2. **Moderation Review Modal:**
   - Full-size image preview (max 800x600px)
   - Moderation labels with color-coded badges (red for high confidence)
   - Approve (green) and Reject (red) action buttons
   - Notes textarea for admin comments

3. **Moderation Stats Dashboard:**
   - Summary cards: Total Scanned, Auto-Approved, Flagged, Rejection Rate
   - Bar chart: Flags by Category
   - Line chart: Moderation trends over time

### Accessibility Considerations

- Image previews have `alt` attributes with moderation labels
- Action buttons keyboard-accessible (Tab navigation)
- Modal focus trap and return focus after close
- WCAG AA contrast for badge colors

---

## Dependencies

### Blocked By:

- **WISH-2013** (File Upload Security Hardening) - Required for upload flow to exist
  - Moderation triggers after virus scan completes
  - S3 infrastructure and presigned URLs must be in place

### Blocks:

- Future content moderation features (text moderation, user reporting)
- Public wishlist sharing (requires content moderation before public exposure)

### Internal Package Dependencies:

- `@repo/api-client` - Zod schemas for moderation results
- `@repo/logger` - Moderation audit logging
- `@repo/app-component-library` - Admin UI components (table, modal, badges)

### External Dependencies:

- **AWS Rekognition:** AI/ML moderation service
  - Pricing: ~$0.001 per image
  - Requires IAM policy updates

---

## Risks & Mitigations

### Risk 1: High False Positive Rate from AWS Rekognition

**Description:** AWS Rekognition may incorrectly flag legitimate LEGO images (e.g., minifigures perceived as nudity).

**Likelihood:** Medium
**Impact:** High (User frustration, content hidden unnecessarily)

**Mitigation:**
- Set conservative confidence thresholds (≥ 90% for auto-flagging)
- Admin review process catches false positives
- Log all false positives for analysis and threshold tuning
- If false positive rate > 5%, adjust thresholds or switch to Google Cloud Vision

---

### Risk 2: Moderation Service Costs Scale with User Growth

**Description:** AWS Rekognition charges $0.001 per image. At 100K images/month, costs reach $100/month.

**Likelihood:** High (as platform grows)
**Impact:** Medium (Budget impact)

**Mitigation:**
- Monitor moderation costs in CloudWatch metrics
- Set budget alerts at $50/month threshold
- Optimize by caching moderation results (do not re-scan same image)
- Consider batch processing or tiered pricing at scale

---

### Risk 3: Async Moderation Creates UX Gap for Flagged Content

**Description:** User uploads image, sees success, but image disappears if flagged. No immediate feedback.

**Likelihood:** Low (most images auto-approved)
**Impact:** Medium (User confusion)

**Mitigation:**
- Display "Processing" badge on images with 'pending-scan' status
- Show "Under Review" badge for 'pending-review' images
- Email notification if image flagged (notification system out of scope for MVP)
- Document expected behavior in user help docs

---

### Risk 4: Admin Review Backlog Grows Faster Than Capacity

**Description:** If flagging rate exceeds admin review capacity, queue grows indefinitely.

**Likelihood:** Medium
**Impact:** High (User experience degradation, content stuck in review)

**Mitigation:**
- Monitor queue length and review time metrics
- Set SLA for review completion (< 24 hours target)
- Alert operations team if queue exceeds 100 items
- Increase moderation team capacity if sustained backlog

---

## Definition of Done

- [ ] AI/ML content moderation integration implemented (AC1)
- [ ] Automatic flagging based on thresholds (AC2)
- [ ] Manual review queue for flagged content (AC3)
- [ ] Image preview with moderation labels (AC4)
- [ ] Approve flagged content endpoint and UI (AC5)
- [ ] Reject flagged content endpoint and UI (AC6)
- [ ] Moderation status stored in database (AC7)
- [ ] Moderation metrics and stats (AC8)
- [ ] Moderation service adapter pattern (AC9)
- [ ] Async moderation does not block upload (AC10)
- [ ] Low-confidence detections auto-approved (AC11)
- [ ] Medium-confidence detections auto-flagged (AC12)
- [ ] Admin authorization for moderation endpoints (AC13)
- [ ] Moderation test coverage with MSW mocks (AC14)
- [ ] Documentation updated (AC15)
- [ ] All unit tests pass (25+ for moderation service)
- [ ] All integration tests pass (20+ for admin endpoints)
- [ ] All component tests pass (15+ for admin UI)
- [ ] Playwright E2E tests pass (5+ for admin workflow)
- [ ] No TypeScript errors
- [ ] No ESLint errors
- [ ] Code reviewed and approved
- [ ] Database schema migration deployed
- [ ] AWS Rekognition IAM policy deployed
- [ ] Staging environment validation complete
- [ ] Moderation metrics verified in CloudWatch

---

## Out of Scope (Future Work)

- **User Reporting Mechanism:** Manual user reporting of inappropriate content → Defer to WISH-2018 (Community Reporting)
- **Appeal Process:** User appeals for moderation decisions → Defer to WISH-2019 (Moderation Appeals)
- **Text Content Moderation:** Comments, descriptions, user-generated text → Defer to separate story
- **Video Content Moderation:** Not applicable to wishlist feature (image-only)
- **Background Scan of Existing Images:** Retroactive scanning of pre-existing images → Defer to WISH-2020 (Retroactive Scan)
- **Multi-Language Content Detection:** Text-based moderation not in scope
- **Custom ML Model Training:** Use off-the-shelf AWS Rekognition for MVP, defer custom models to future

---

## Notes

### Implementation Approach (Recommended):

1. **Database Schema First:**
   - Create `moderation_results` table
   - Add `moderation_status` column to `wishlist_items`
   - Run migration in staging environment

2. **Moderation Service (Backend):**
   - Implement AWS Rekognition adapter
   - Implement content scanner with threshold logic
   - Add async trigger to upload flow (after virus scan)
   - Write unit tests for moderation service (25+ tests)

3. **Admin Endpoints:**
   - Implement moderation queue endpoint (GET /api/admin/moderation/queue)
   - Implement approve/reject endpoints
   - Implement stats endpoint
   - Add admin authorization middleware
   - Write integration tests (20+ tests)

4. **Admin UI:**
   - Create ModerationQueue page component
   - Create ModerationCard component with image preview
   - Implement approve/reject actions with RTK Query
   - Add component tests (15+ tests)

5. **Integration Testing:**
   - Extend MSW handlers for moderation API mocks
   - Create test fixtures for flagged content scenarios
   - Write Playwright E2E tests (5+ tests)

6. **Staging Validation:**
   - Deploy to staging environment
   - Upload test images (clean, flagged, edge cases)
   - Validate auto-approval and auto-flagging thresholds
   - Test admin review workflow end-to-end
   - Verify moderation metrics in CloudWatch

### Quality Gates:

- All moderation tests pass without errors
- False positive rate < 5% in staging validation
- Average moderation scan time < 2 seconds
- Admin review workflow completes in < 30 seconds per item
- Moderation metrics visible in CloudWatch dashboards

---

## Open Questions

_None. All major questions resolved during story creation._

