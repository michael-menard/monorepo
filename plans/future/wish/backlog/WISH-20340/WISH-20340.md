---
doc_type: story
title: "WISH-20340: Multi-region Redis replication (global latency optimization)"
story_id: WISH-20340
story_prefix: WISH
status: backlog
follow_up_from: WISH-2124
phase: 5
created_at: "2026-01-30T00:00:00-07:00"
updated_at: "2026-01-30T00:00:00-07:00"
depends_on: [WISH-2124]
estimated_points: 5
sizing_warning: false
priority: P3
complexity: High
---

# WISH-20340: Multi-region Redis replication (global latency optimization)

## Follow-up Context

**Parent Story**: WISH-2124
**Source**: QA Discovery Notes - Enhancement Opportunity #3
**Original Finding**: Multi-region Redis replication (global latency optimization)
**Category**: Enhancement Opportunity
**Impact**: Medium (global user experience)
**Effort**: High (multi-region infrastructure)

### Background

WISH-2124 deployed Redis infrastructure with single-region ElastiCache for feature flag caching. While sufficient for MVP and North American users, global applications benefit from multi-region Redis replication to reduce latency for users in distant geographic regions (Europe, Asia-Pacific, etc.).

Single-region Redis forces all feature flag cache reads to traverse long network paths, increasing P95 latency from <100ms (local region) to potentially 200-500ms (cross-continental). Multi-region replication enables read-local caching with eventual consistency for flag data.

## Context

Feature flag caching in WISH-2124 uses single-region AWS ElastiCache (e.g., `us-east-1`). For applications serving global audiences, this architecture creates geographic latency penalties:

1. **Cross-region latency**: Users in `eu-west-1` or `ap-southeast-1` experience 150-400ms additional latency for cache reads
2. **Lambda cold starts**: Each region's Lambda cold start must connect to primary region's Redis, compounding latency
3. **Network egress costs**: Cross-region Redis traffic incurs AWS data transfer charges ($0.02/GB)

Multi-region Redis replication addresses these issues by deploying read replicas in multiple AWS regions, enabling Lambda functions to read from their local region's Redis instance. Write operations (flag updates) still go to the primary region, with asynchronous replication to read replicas (eventual consistency acceptable for feature flags).

**Key Dependencies:**
- WISH-2124 must be complete with stable Redis infrastructure and `RedisCacheAdapter`
- Multi-region Lambda deployment must be active (or planned)
- Application must tolerate eventual consistency (flag changes propagate within 1-3 seconds)

**Production Readiness Signal:**
This story becomes critical when:
- Application deployed in 2+ AWS regions for global availability
- Cross-region P95 latency > 150ms for feature flag reads
- >20% of traffic originates from regions outside primary Redis region

## Goal

Deploy multi-region Redis replication for feature flag caching to optimize latency for global users. Enable each AWS region's Lambda functions to read from local Redis read replicas while maintaining centralized write control.

**Success Criteria:**
- P95 cache read latency < 50ms in all deployed regions (vs. 200-500ms cross-region baseline)
- Replication lag < 2 seconds (flag updates propagate globally within 2s)
- Zero data loss on primary region failure (automated failover to read replica promoted to primary)
- Infrastructure cost increase < $50/month per additional region

## Non-goals

- **Synchronous multi-region writes**: Write operations remain centralized to primary region. Synchronous cross-region replication adds complexity and latency without benefit for feature flags.
- **Active-active replication**: All write operations go to primary region. Active-active (multi-master) replication deferred to future story if needed.
- **Multi-region database replication**: This story is Redis-only. Database (Aurora) multi-region replication is separate infrastructure story.
- **Read replica load balancing**: Each region uses its single local read replica. Load balancing across multiple replicas per region deferred.
- **Conflict resolution for concurrent writes**: Not applicable - single primary region handles all writes sequentially.
- **Real-time replication monitoring dashboard**: CloudWatch metrics sufficient for MVP. Grafana/Prometheus dashboards deferred.
- **Cross-region VPN peering optimization**: Use AWS PrivateLink or VPC peering for lowest latency, but optimization deferred to infrastructure team.

## Scope

### Packages Affected

**Backend Infrastructure:**
- `apps/api/lego-api/core/cache/redis-client.ts` - Detect region and connect to local read replica or primary
- `apps/api/lego-api/domains/config/adapters/RedisCacheAdapter.ts` - Route writes to primary, reads to local replica
- Infrastructure code (CDK/Terraform): ElastiCache Global Datastore or manual replication group configuration

**Environment Configuration:**
- `REDIS_PRIMARY_URL` - Primary region Redis endpoint (for writes)
- `REDIS_REPLICA_URL` - Local region read replica endpoint (for reads)
- `AWS_REGION` - Lambda environment variable to detect current region

### Endpoints Impacted

**No API contract changes** - transparent infrastructure optimization.

Existing endpoints behavior:
- `GET /api/config/flags/:flagKey` - Reads from local Redis replica (lower latency)
- `PATCH /api/admin/flags/:flagKey` - Writes to primary Redis, invalidates primary cache (replicates to replicas)
- `GET /api/config/flags` - Reads from local Redis replica (lower latency)

### Infrastructure Components

**AWS ElastiCache Global Datastore (Recommended Approach):**
- Primary cluster: `us-east-1` (existing from WISH-2124)
- Secondary clusters: `eu-west-1`, `ap-southeast-1` (read replicas)
- Replication mode: Asynchronous (sub-second lag typical)
- Automatic failover: Manual or automated promotion of secondary to primary
- Estimated cost: +$15-30/month per secondary region

**Alternative: Manual Replication Group:**
- Use Redis replication (`REPLICAOF` command) if Global Datastore not available
- Configure primary-replica relationship manually
- Failover: Manual promotion via AWS CLI/Console

**Lambda Configuration per Region:**
- `REDIS_PRIMARY_URL`: Points to primary region (us-east-1)
- `REDIS_REPLICA_URL`: Points to local region's read replica
- Logic: Write to primary, read from local replica

## Acceptance Criteria

### AC 1: ElastiCache Global Datastore Setup
**Given** the need for multi-region Redis replication
**When** provisioning infrastructure
**Then** create ElastiCache Global Datastore with primary cluster in `us-east-1`
**And** add secondary clusters in `eu-west-1` and `ap-southeast-1`
**And** configure asynchronous replication from primary to secondaries
**And** verify replication lag < 2 seconds under normal load

**Evidence:**
- AWS Console shows Global Datastore with 3 clusters (primary + 2 secondaries)
- CloudWatch metric `ReplicationLag` < 2000ms for all secondaries
- Infrastructure-as-code (CDK/Terraform) defines Global Datastore configuration

### AC 2: Region-Aware Redis Client
**Given** Lambda functions deployed in multiple regions
**When** initializing Redis client
**Then** detect current AWS region from `AWS_REGION` environment variable
**And** if region matches primary region (`us-east-1`): use `REDIS_PRIMARY_URL` for all operations
**And** if region is secondary region: use `REDIS_REPLICA_URL` for reads, `REDIS_PRIMARY_URL` for writes

**Evidence:**
- `redis-client.ts` inspects `process.env.AWS_REGION`
- Unit tests verify region detection logic
- Integration tests in `us-east-1` and `eu-west-1` confirm correct endpoint usage

### AC 3: Read-Write Split in RedisCacheAdapter
**Given** the need to optimize latency while ensuring write consistency
**When** implementing cache operations
**Then** route `get()` calls to local read replica (low latency)
**And** route `set()` and `delete()` calls to primary region (centralized writes)
**And** accept eventual consistency (writes may not be immediately visible in other regions)

**Evidence:**
- `RedisCacheAdapter.get()` uses `REDIS_REPLICA_URL`
- `RedisCacheAdapter.set()` and `delete()` use `REDIS_PRIMARY_URL`
- Integration tests verify write-to-primary, read-from-replica behavior
- Replication lag tests confirm updates visible in replicas within 2 seconds

### AC 4: Graceful Degradation on Replica Failure
**Given** a read replica becomes unavailable (network issue, failover)
**When** attempting to read from local replica
**Then** retry against primary region Redis (fallback)
**And** log degraded mode with structured logging
**And** respond with 200 status (no client-facing errors)

**Evidence:**
- Integration test: Stop `eu-west-1` replica, verify `eu-west-1` Lambda falls back to primary
- CloudWatch logs: "replica_unavailable=true, fallback_to_primary=true"
- No 500 errors during replica outage

### AC 5: Primary Region Failover (Manual Promotion)
**Given** primary region (`us-east-1`) experiences outage
**When** operations team initiates manual failover
**Then** promote `eu-west-1` secondary to primary
**And** update `REDIS_PRIMARY_URL` environment variable in all Lambdas to new primary
**And** reconfigure replication topology (new primary, remaining regions as secondaries)
**And** resume normal operations within 15 minutes

**Evidence:**
- Runbook documents failover procedure (step-by-step AWS Console/CLI commands)
- Failover drill in staging: Promote secondary → update env vars → validate
- CloudWatch alarm triggers on primary unavailability (auto-creates incident ticket)

### AC 6: Replication Lag Monitoring
**Given** asynchronous replication between regions
**When** monitoring infrastructure health
**Then** publish CloudWatch metric `ReplicationLag` for each secondary cluster
**And** trigger CloudWatch alarm if lag > 5 seconds (threshold for investigation)
**And** send SNS notification to operations team on alarm

**Evidence:**
- CloudWatch dashboard shows `ReplicationLag` for `eu-west-1` and `ap-southeast-1`
- Alarm configured: `ReplicationLag > 5000ms for 2 consecutive periods`
- SNS topic sends email/Slack notification to on-call engineer

### AC 7: Cross-Region Latency Validation
**Given** multi-region Redis deployment
**When** running latency tests from each region
**Then** P95 cache read latency from `us-east-1` Lambda < 50ms (local replica)
**And** P95 cache read latency from `eu-west-1` Lambda < 50ms (local replica)
**And** P95 cache read latency from `ap-southeast-1` Lambda < 50ms (local replica)
**And** P95 latency improvement: >75% vs. baseline (cross-region reads)

**Evidence:**
- Load tests run from each region (Artillery/k6)
- CloudWatch metrics: `CacheReadLatency_P95` < 50ms per region
- Before/after latency comparison: `eu-west-1` improved from 250ms → 40ms

### AC 8: Write Latency Acceptance
**Given** all writes go to primary region (cross-region for non-primary regions)
**When** updating a feature flag from `eu-west-1` Lambda
**Then** write latency may be 150-200ms (network to primary region)
**And** this is acceptable (admin operations are infrequent, not latency-sensitive)
**And** response includes acknowledgment: "Flag updated, changes propagating globally"

**Evidence:**
- Integration test: PATCH from `eu-west-1` → measures latency → confirms write succeeded
- Admin UI shows "Propagating..." status for 2 seconds after update
- CloudWatch logs: "write_region=us-east-1, request_region=eu-west-1"

### AC 9: Environment Variable Configuration
**Given** multiple Redis endpoints per region
**When** configuring Lambda environment variables
**Then** set `REDIS_PRIMARY_URL=redis://<us-east-1-endpoint>:6379` in all regions
**And** set `REDIS_REPLICA_URL=redis://<local-region-endpoint>:6379` per region
**And** use AWS Secrets Manager for production (not plaintext env vars)

**Evidence:**
- Lambda configuration shows `REDIS_PRIMARY_URL` and `REDIS_REPLICA_URL`
- Secrets Manager stores endpoints securely
- Infrastructure code injects correct replica URL per region

### AC 10: Cost Monitoring for Multi-Region Redis
**Given** additional secondary clusters incur costs
**When** monitoring infrastructure spend
**Then** track ElastiCache costs per region in Cost Explorer
**And** verify total Redis cost < $100/month (primary + 2 secondaries)
**And** alert if cost exceeds $150/month threshold

**Evidence:**
- Cost Explorer tags: `Service=ElastiCache`, `Region=us-east-1|eu-west-1|ap-southeast-1`
- Billing alarm at $150/month
- Monthly cost review: Expected ~$45-90/month (3 regions × $15-30/region)

### AC 11: Cache Invalidation Propagation
**Given** a flag update invalidates cache in primary region
**When** `delete()` called on primary Redis
**Then** replication propagates deletion to secondary regions
**And** next read from secondary regions triggers cache miss → database read → re-cache with updated value
**And** invalidation visible in all regions within 2 seconds

**Evidence:**
- Integration test: Update flag → delete from primary → wait 2s → verify secondaries show cache miss
- CloudWatch logs: "cache_invalidated=true" in all regions within 2s window
- E2E test: Update flag → poll from all regions → confirm updated value within 3s

### AC 12: Disaster Recovery Test
**Given** the need to validate failover procedures
**When** running quarterly DR drill
**Then** simulate primary region outage (block network to `us-east-1` Redis)
**And** promote `eu-west-1` secondary to primary (manual AWS CLI command)
**And** update all Lambda `REDIS_PRIMARY_URL` to new primary
**And** validate all regions can read/write to new primary
**And** complete recovery within 15 minutes RTO

**Evidence:**
- DR runbook: Step-by-step failover procedure
- Staging drill: Outage → promotion → env var update → validation → rollback
- Incident report template with timeline and lessons learned

## Reuse Plan

### Packages to Reuse
- **`apps/api/lego-api/core/cache/redis-client.ts`**: Extend existing Redis client to support read-write split
- **`apps/api/lego-api/domains/config/adapters/RedisCacheAdapter.ts`**: Enhance with region-aware routing
- **`@repo/logger`**: Structured logging for replication lag, failover events
- **`packages/backend/db`**: Database fallback on cache failure (unchanged from WISH-2124)

### Patterns to Reuse
- **Graceful degradation**: Similar to WISH-2124's database fallback on Redis failure
- **Environment-based configuration**: Same pattern as `DATABASE_URL`, `REDIS_URL` in WISH-2124
- **Hexagonal architecture**: No changes to `CacheAdapter` interface or `FlagService` business logic
- **Retry logic with exponential backoff**: Reuse from WISH-2124 for replica connection failures

### Testing Patterns to Reuse
- **Docker Compose for local simulation**: Add multi-Redis setup (1 primary + 1 replica)
- **Integration tests**: Similar to WISH-2124's Redis integration tests, extended for multi-region
- **Load testing**: Reuse Artillery/k6 scripts, run from multiple regions

## Architecture Notes

### Read-Write Split Pattern

**Architecture Principle**: Optimize for read latency (frequent) while accepting write latency (infrequent).

**Implementation:**
```typescript
// redis-client.ts
export const createRedisClients = () => {
  const region = process.env.AWS_REGION!
  const primaryUrl = process.env.REDIS_PRIMARY_URL!
  const replicaUrl = process.env.REDIS_REPLICA_URL || primaryUrl

  const primaryClient = new Redis(primaryUrl, { /* config */ })
  const replicaClient = region === 'us-east-1' ? primaryClient : new Redis(replicaUrl, { /* config */ })

  return { primaryClient, replicaClient }
}
```

**RedisCacheAdapter Enhancement:**
```typescript
export class RedisCacheAdapter implements CacheAdapter {
  constructor(
    private primaryRedis: Redis, // For writes
    private replicaRedis: Redis   // For reads
  ) {}

  async get(key: string): Promise<string | null> {
    try {
      // Read from local replica (low latency)
      return await this.replicaRedis.get(`flag:${key}`)
    } catch (error) {
      logger.error('Replica read failed, falling back to primary', { key, error })
      // Fallback to primary
      return await this.primaryRedis.get(`flag:${key}`)
    }
  }

  async set(key: string, value: string, ttlSeconds: number): Promise<void> {
    try {
      // Write to primary (centralized, propagates to replicas)
      await this.primaryRedis.setex(`flag:${key}`, ttlSeconds, value)
    } catch (error) {
      logger.error('Primary write failed', { key, error })
      // Non-blocking: Stale cache expires via TTL
    }
  }

  async delete(key: string): Promise<void> {
    try {
      // Invalidate on primary (propagates to replicas)
      await this.primaryRedis.del(`flag:${key}`)
    } catch (error) {
      logger.error('Primary invalidation failed', { key, error })
    }
  }
}
```

**Service Layer (Unchanged):**
- `FlagService` remains unaware of multi-region complexity
- Hexagonal architecture isolates infrastructure changes from business logic

### Replication Topology

**Global Datastore Architecture:**
```
Primary Region (us-east-1):
  ElastiCache Cluster: redis-primary.use1.cache.amazonaws.com:6379
  Role: Accepts writes, serves reads for us-east-1 Lambdas

Secondary Region (eu-west-1):
  ElastiCache Cluster: redis-replica.euw1.cache.amazonaws.com:6379
  Role: Read-only replica, serves reads for eu-west-1 Lambdas
  Replication: Asynchronous from primary

Secondary Region (ap-southeast-1):
  ElastiCache Cluster: redis-replica.apse1.cache.amazonaws.com:6379
  Role: Read-only replica, serves reads for ap-southeast-1 Lambdas
  Replication: Asynchronous from primary
```

**Failover Flow (Manual):**
1. Primary region outage detected (CloudWatch alarm)
2. Operations team promotes `eu-west-1` replica to primary (AWS Console/CLI)
3. Update `REDIS_PRIMARY_URL` in all Lambdas to new primary endpoint
4. `ap-southeast-1` replica reconfigures to replicate from new primary
5. Resume normal operations (new primary accepts writes)

### Eventual Consistency Model

**Acceptable for Feature Flags:**
- Flag updates are infrequent (admin-initiated)
- Users tolerate 1-3 second propagation delay
- TTL (5 minutes) ensures eventual consistency even if replication lags

**Not Acceptable For:**
- Real-time user permissions (use database reads for consistency)
- Financial transactions (use strongly consistent database)
- Session tokens (use DynamoDB global tables for multi-region consistency)

## Test Plan

See `_pm/TEST-PLAN.md` for comprehensive test plan including:
- Happy path tests (multi-region read latency optimization)
- Error cases (replica failure, primary failure, replication lag)
- Edge cases (split-brain scenarios, network partitions)
- Backend testing requirements (multi-region load tests, failover drills)
- Success criteria and rollback plan

## UI/UX Notes

See `_pm/UIUX-NOTES.md` - **SKIPPED** (no UI changes in this infrastructure story)

Admin UI may optionally show:
- "Flag update propagating to global regions..." message after PATCH
- Region selector in admin panel (future enhancement)

## Dev Feasibility Review

See `_pm/DEV-FEASIBILITY.md` for detailed feasibility analysis including:
- MVP-critical risks (primary region failure, replication lag spikes)
- Missing requirements (failover automation decision, region selection strategy)
- Change surface analysis
- MVP evidence expectations
- Confidence: Medium (depends on ElastiCache Global Datastore availability)

## Risks & Mitigations

### Risk 1: Replication Lag Spikes During High Traffic
**Likelihood**: Medium
**Impact**: Medium (stale cache reads for 5-10 seconds)

**Mitigation:**
- CloudWatch alarm on `ReplicationLag > 5s`
- TTL ensures stale cache expires (worst case: 5 minutes)
- Monitor lag during load tests, scale Redis instance if needed
- Acceptable for feature flags (not real-time critical)

### Risk 2: Primary Region Failure Requires Manual Intervention
**Likelihood**: Low
**Impact**: High (15-minute RTO for failover)

**Mitigation:**
- Documented runbook with step-by-step failover procedure
- Quarterly DR drills in staging to validate process
- CloudWatch alarm auto-creates incident ticket for on-call engineer
- Future enhancement: Automated failover with AWS Global Datastore auto-promotion

### Risk 3: Split-Brain Scenario (Two Primaries)
**Likelihood**: Very Low
**Impact**: High (data inconsistency)

**Mitigation:**
- Manual failover process includes verification steps (ensure old primary is unreachable)
- Infrastructure-as-code prevents multiple writable primaries
- Monitoring detects conflicting write patterns (CloudWatch metrics)
- Flag updates are idempotent (same update can apply multiple times safely)

### Risk 4: Network Partition Between Regions
**Likelihood**: Low
**Impact**: Medium (replicas serve stale cache, primary unavailable)

**Mitigation:**
- Graceful degradation: Replicas fall back to database on primary unreachable
- TTL ensures cache expires (users see fresh data within 5 minutes)
- VPC peering or AWS PrivateLink for reliable cross-region connectivity
- Monitor network latency with CloudWatch metrics

### Risk 5: Cost Overruns from Additional Regions
**Likelihood**: Low
**Impact**: Low (predictable infrastructure cost)

**Mitigation:**
- Billing alarm at $150/month threshold
- Start with 2 secondary regions (eu-west-1, ap-southeast-1)
- Use `t3.micro` instances (cheapest ElastiCache tier)
- Monthly cost review and right-sizing process

## Deployment Strategy

### Phase 1: Infrastructure Setup (Week 1)
1. Provision ElastiCache Global Datastore in staging
2. Configure primary cluster (`us-east-1`) + secondaries (`eu-west-1`, `ap-southeast-1`)
3. Validate replication lag < 2s under load tests
4. Document failover procedures (runbook)

### Phase 2: Code Changes (Week 1-2)
1. Extend `redis-client.ts` with region detection and dual-client creation
2. Update `RedisCacheAdapter` with read-write split logic
3. Add unit tests for region detection and routing
4. Add integration tests with Docker multi-Redis setup

### Phase 3: Staging Deployment (Week 2)
1. Deploy multi-region Lambdas to staging (us-east-1, eu-west-1)
2. Configure `REDIS_PRIMARY_URL` and `REDIS_REPLICA_URL` per region
3. Run cross-region latency tests (validate <50ms P95)
4. Simulate primary failure (test failover procedures)

### Phase 4: Production Canary (Week 2-3)
1. Deploy to production `eu-west-1` only (5% traffic)
2. Monitor for 24 hours: Latency, replication lag, error rate
3. If metrics pass → enable `ap-southeast-1` (25% traffic)
4. If metrics pass → promote to 100% (all regions active)

### Phase 5: Post-Deployment Validation (Week 3-4)
1. Monitor CloudWatch metrics for 1 week
2. Conduct DR drill (simulate primary failure, execute failover)
3. Verify Cost Explorer shows expected charges (~$45-90/month)
4. Customer-reported issues: Zero tolerance (rollback if >1 latency complaint)

## Related Stories

**Dependencies:**
- **WISH-2124**: Redis infrastructure setup (provides single-region Redis and `RedisCacheAdapter`)

**Follow-ups:**
- **WISH-TBD**: Automated failover for Redis primary region (eliminate manual promotion)
- **WISH-TBD**: Active-active Redis replication (multi-master writes, conflict resolution)
- **WISH-TBD**: Redis Cluster mode per region (high availability within region)

**Parallel Enhancements:**
- **WISH-2125**: Redis Cluster mode for high availability (can combine with multi-region)
- **WISH-2126**: Cache warming strategy (pre-populate replicas on cold start)

## Definition of Done

- [ ] All 12 acceptance criteria pass
- [ ] Unit tests pass (15+ tests for region detection and routing)
- [ ] Integration tests pass (10+ tests with Docker multi-Redis)
- [ ] Load tests pass from all regions (P95 latency < 50ms)
- [ ] Replication lag < 2 seconds under normal load (validated over 24 hours)
- [ ] Failover drill successful (staging: promote secondary, validate, rollback)
- [ ] CloudWatch alarms configured (replication lag, cost threshold)
- [ ] Documentation updated (runbook, architecture docs, cost monitoring)
- [ ] Cost Explorer confirms ~$45-90/month (3 regions)
- [ ] No customer-reported latency issues for 1 week post-deployment
- [ ] TypeScript compilation passes
- [ ] ESLint passes with no errors
- [ ] Code review approved

## Open Questions

_All questions resolved during elaboration._

## Token Budget

### Phase Summary

| Phase | Estimated | Actual | Delta | Notes |
|-------|-----------|--------|-------|-------|
| Story Generation | ~20k | — | — | Complex multi-region infrastructure |
| Elaboration | ~15k | — | — | Follow-up from WISH-2124 |
| Implementation | ~25k | — | — | Multi-region setup + failover testing |
| Code Review | ~8k | — | — | Infrastructure + region routing |
| **Total** | ~68k | — | — | Large infrastructure story |

## Agent Log

| Timestamp (America/Denver) | Agent | Action | Outputs |
|---|---|---|---|
| 2026-01-30 00:00 | pm-story-followup-leader | Created follow-up from WISH-2124 finding #3 | WISH-20340.md |

---
