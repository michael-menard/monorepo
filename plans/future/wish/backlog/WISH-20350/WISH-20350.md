---
doc_type: story
title: "WISH-20350: Cache analytics dashboard (Grafana/Prometheus integration)"
story_id: WISH-20350
story_prefix: WISH
status: backlog
follow_up_from: WISH-2124
phase: 3
created_at: "2026-01-30T00:00:00Z"
updated_at: "2026-01-30T00:00:00Z"
depends_on: [WISH-2124]
estimated_points: 3
priority: P2
complexity: Medium
---

# WISH-20350: Cache analytics dashboard (Grafana/Prometheus integration)

## Follow-up Context

**Parent Story**: WISH-2124
**Source**: QA Discovery Notes - Enhancement Opportunity #4
**Original Finding**: Cache analytics dashboard (Grafana/Prometheus integration)
**Category**: Enhancement Opportunity
**Impact**: Medium (observability improvement)
**Effort**: Medium (new monitoring infrastructure)

### Background

WISH-2124 implements Redis caching infrastructure with CloudWatch metrics for basic monitoring (cache hit rate, connection errors, response latency, active connections). While CloudWatch provides essential operational metrics, it lacks advanced analytics capabilities for:

1. **Historical trend analysis**: Long-term cache performance patterns, seasonal variations
2. **Custom metric correlation**: Relating cache behavior to business metrics (user activity, feature adoption)
3. **Advanced alerting**: Multi-metric thresholds, anomaly detection, predictive alerts
4. **Team dashboards**: Centralized observability across all services, not just feature flags

Grafana/Prometheus integration provides production-grade observability with:
- Custom dashboards for cache performance visualization
- Long-term metric retention (CloudWatch retains detailed metrics for 15 days)
- Open-source ecosystem (plugins, alerting integrations, community templates)
- Cross-service correlation (combine cache metrics with application/database metrics)

## Context

WISH-2124 establishes Redis caching with CloudWatch metrics sufficient for MVP operational monitoring. As the platform scales and additional services adopt Redis (wishlist caching, session storage, rate limiting), centralized analytics become critical for:

1. **Capacity planning**: Predicting when to scale ElastiCache instance size based on memory usage trends
2. **Performance optimization**: Identifying cache key patterns with low hit rates for optimization
3. **Cost optimization**: Correlating cache hit rates with database query costs to justify infrastructure spend
4. **Incident response**: Visualizing cache behavior during outages or performance degradations

This story integrates Grafana (visualization) and Prometheus (metrics collection) with AWS CloudWatch as the metric source. Prometheus scrapes CloudWatch metrics via the CloudWatch Exporter, and Grafana visualizes them in customizable dashboards.

**Key Dependencies:**
- WISH-2124 must be complete with CloudWatch metrics emitting (cache_hit_rate, redis_connection_errors, response_latency_p95, active_connections)
- Production ElastiCache cluster running with stable workload (for meaningful metrics)

**Production Readiness Signal:**
This story becomes critical when:
- Multiple services use Redis (>2 domains), requiring centralized cache observability
- Cache troubleshooting requires >30 minutes due to CloudWatch query limitations
- Stakeholders request cache performance reports (business case for Redis investment)

## Goal

Implement Grafana/Prometheus analytics dashboard for Redis cache observability. Provide centralized, long-term metric storage and advanced visualization for cache performance, capacity planning, and cost optimization.

**Success Criteria:**
- Grafana dashboard displays real-time cache metrics (hit rate, latency, connection errors)
- Prometheus retains 90 days of metric history (vs. CloudWatch 15 days)
- Alerting thresholds trigger Slack notifications for cache degradation
- Dashboard accessible to engineering team via SSO authentication

## Non-goals

- **Real-time streaming metrics**: Prometheus scrapes at 1-minute intervals. Sub-second granularity out of scope.
- **Multi-region dashboard aggregation**: Single-region dashboard sufficient for MVP. Global view deferred.
- **Custom Prometheus exporters**: Use CloudWatch Exporter for MVP. Direct Redis exporter deferred.
- **Grafana Cloud**: Self-hosted Grafana on EC2/Fargate. Managed service deferred to reduce costs.
- **Advanced anomaly detection**: Basic threshold alerts sufficient. ML-based anomaly detection deferred.
- **Dashboard access for non-engineering users**: Engineering team only. Business user dashboards deferred.

## Scope

### Packages Affected

**Backend Infrastructure:**
- Infrastructure code (CDK/Terraform): Prometheus server (EC2/Fargate), CloudWatch Exporter, Grafana server
- `apps/api/lego-api/core/monitoring/` - CloudWatch metric namespace configuration
- Grafana dashboard JSON: Cache performance dashboard template

**Monitoring Components:**
- **Prometheus**: Metric collection, storage (90-day retention), query engine
- **CloudWatch Exporter**: Scrapes CloudWatch metrics, exposes Prometheus-compatible endpoint
- **Grafana**: Visualization, dashboards, alerting

### Infrastructure Components

**Prometheus Server:**
- Deployment: AWS Fargate container (or EC2 t3.small)
- Storage: EBS volume (50 GB for 90-day retention)
- Scrape interval: 1 minute
- Retention: 90 days
- Estimated cost: ~$20-40/month (Fargate) or ~$10-20/month (EC2)

**CloudWatch Exporter:**
- Deployment: Sidecar container in Prometheus task (Fargate)
- Metrics scraped: `CacheHitRate`, `ConnectionErrors`, `ResponseLatency_P95`, `ActiveConnections` from `AWS/ElastiCache` namespace
- IAM permissions: `cloudwatch:GetMetricStatistics`, `cloudwatch:ListMetrics`

**Grafana Server:**
- Deployment: AWS Fargate container (or EC2 t3.small)
- Storage: RDS PostgreSQL for dashboard/user storage
- Authentication: AWS SSO integration (or basic auth for MVP)
- Estimated cost: ~$20-40/month (Fargate) or ~$10-20/month (EC2)

**Total Estimated Cost:** ~$40-80/month for Prometheus + Grafana infrastructure

### Metrics to Visualize

From WISH-2124 CloudWatch metrics:
1. **Cache Hit Rate**: Percentage of requests served from cache (target: >80%)
2. **Redis Connection Errors**: Count of connection failures (alert threshold: >5/minute)
3. **Response Latency P95**: 95th percentile response time (target: <100ms for cache hits)
4. **Active Connections**: Current Redis connections (alert threshold: >8 sustained)

Additional derived metrics:
5. **Cache Miss Rate**: 100% - cache_hit_rate
6. **Database Fallback Rate**: Percentage of requests falling back to database
7. **ElastiCache Memory Utilization**: From AWS/ElastiCache CloudWatch metrics
8. **Network Throughput**: Bytes in/out to ElastiCache

## Acceptance Criteria

### AC 1: Prometheus Server Deployment
**Given** the need for centralized metric collection
**When** deploying Prometheus infrastructure
**Then** deploy Prometheus 2.x server on AWS Fargate (or EC2 t3.small)
**And** configure 50 GB EBS volume for metric storage (90-day retention)
**And** set scrape interval to 1 minute
**And** expose Prometheus UI at `https://prometheus.internal.example.com` (VPN-protected)

**Evidence:**
- Prometheus UI accessible via VPN
- Storage volume shows ~500 MB/day metric growth (expected for MVP workload)
- Prometheus `/targets` endpoint shows CloudWatch Exporter healthy

### AC 2: CloudWatch Exporter Configuration
**Given** Prometheus needs CloudWatch metrics
**When** configuring CloudWatch Exporter
**Then** deploy CloudWatch Exporter as sidecar container in Prometheus Fargate task
**And** configure IAM role with `cloudwatch:GetMetricStatistics`, `cloudwatch:ListMetrics` permissions
**And** scrape metrics from `AWS/ElastiCache` namespace: `CacheHitRate`, `ConnectionErrors`, `EngineCPUUtilization`, `DatabaseMemoryUsagePercentage`, `NetworkBytesIn`, `NetworkBytesOut`
**And** expose metrics on port 9106 for Prometheus scraping

**Evidence:**
- CloudWatch Exporter `/metrics` endpoint returns Prometheus-formatted metrics
- Prometheus successfully scrapes CloudWatch Exporter (visible in Prometheus UI `/targets`)
- ElastiCache metrics appear in Prometheus query interface

### AC 3: Grafana Server Deployment
**Given** the need for dashboard visualization
**When** deploying Grafana infrastructure
**Then** deploy Grafana 10.x server on AWS Fargate (or EC2 t3.small)
**And** use RDS PostgreSQL for Grafana database (dashboard/user storage)
**And** expose Grafana UI at `https://grafana.internal.example.com` (VPN-protected)
**And** configure Prometheus as data source in Grafana

**Evidence:**
- Grafana UI accessible via VPN
- Prometheus data source successfully queries metrics (test query returns data)
- Grafana health check passes (database connection healthy)

### AC 4: Cache Performance Dashboard
**Given** the need to visualize Redis cache metrics
**When** creating Grafana dashboard
**Then** create "Redis Cache Performance" dashboard with panels:
  1. **Cache Hit Rate (%)**: Time series graph, 24-hour window, 80% threshold line
  2. **Response Latency P95 (ms)**: Time series graph, 100ms threshold line
  3. **Connection Errors (count/min)**: Time series graph, alert on >5/minute
  4. **Active Connections**: Time series graph, alert on >8 sustained
  5. **Memory Utilization (%)**: From ElastiCache CloudWatch metrics
  6. **Network Throughput (MB/s)**: Bytes in/out combined

**Evidence:**
- Dashboard JSON exported and committed to repository (`infrastructure/grafana/dashboards/redis-cache.json`)
- All 6 panels display live data
- Dashboard accessible via Grafana UI

### AC 5: Alert Configuration
**Given** the need for proactive cache issue detection
**When** configuring Grafana alerts
**Then** create alert rules:
  1. Cache hit rate < 70% for 10 minutes → Slack #engineering channel
  2. Connection errors > 5/minute for 5 minutes → Slack #engineering channel (critical)
  3. Response latency P95 > 200ms for 10 minutes → Slack #engineering channel
  4. Active connections > 8 for 20 minutes → Slack #engineering channel (capacity warning)

**Evidence:**
- Alert rules configured in Grafana
- Test alerts triggered successfully (manual threshold breach simulation)
- Slack messages received in #engineering channel with metric values and dashboard links

### AC 6: 90-Day Metric Retention
**Given** the need for long-term trend analysis
**When** Prometheus stores metrics
**Then** configure retention period to 90 days
**And** automatically delete metrics older than 90 days
**And** monitor storage usage (alert if >80% full)

**Evidence:**
- Prometheus configuration file (`prometheus.yml`) shows `--storage.tsdb.retention.time=90d`
- Storage volume usage monitored via CloudWatch
- Metrics queryable for 90-day window (after initial collection period)

### AC 7: IAM Permissions for CloudWatch Exporter
**Given** CloudWatch Exporter needs AWS API access
**When** configuring IAM role
**Then** attach managed policy or inline policy with:
  - `cloudwatch:GetMetricStatistics`
  - `cloudwatch:ListMetrics`
  - Scoped to `AWS/ElastiCache` namespace only (least privilege)

**Evidence:**
- IAM policy document in infrastructure code (CDK/Terraform)
- CloudWatch Exporter successfully scrapes metrics (no permission errors in logs)
- AWS CLI: `aws iam get-role-policy` shows correct permissions

### AC 8: Dashboard Access Control
**Given** the need for secure dashboard access
**When** configuring Grafana authentication
**Then** enable AWS SSO integration (or basic auth for MVP)
**And** restrict access to engineering team members only
**And** require VPN connection for Grafana UI access

**Evidence:**
- Grafana login page requires SSO authentication (or username/password)
- Unauthorized users cannot access dashboard (401 error)
- Dashboard accessible only via VPN (public internet access blocked)

### AC 9: Cost Monitoring
**Given** Grafana/Prometheus infrastructure incurs monthly costs
**When** operating the monitoring stack
**Then** CloudWatch billing alarm triggers at $100/month threshold (Prometheus + Grafana + RDS)
**And** Cost Explorer tagged for monitoring infrastructure (`Service=Monitoring`, `Feature=CacheAnalytics`)
**And** Monthly cost review process documented

**Evidence:**
- CloudWatch billing alarm configured
- Cost Explorer shows Prometheus/Grafana line items
- Documentation: `docs/infrastructure/monitoring-costs.md`

### AC 10: Dashboard Export and Version Control
**Given** the need for dashboard portability and disaster recovery
**When** creating or updating dashboards
**Then** export dashboard JSON to repository (`infrastructure/grafana/dashboards/`)
**And** commit dashboard changes with descriptive commit messages
**And** document dashboard import process for disaster recovery

**Evidence:**
- Dashboard JSON files in repository
- Git history shows dashboard evolution
- Documentation: `docs/infrastructure/grafana-dashboard-management.md`

## Reuse Plan

### Packages to Reuse
- **Infrastructure code (CDK/Terraform)**: Existing VPC, security groups, IAM patterns from WISH-2124
- **CloudWatch metrics**: Already emitting from WISH-2124 (cache_hit_rate, connection_errors, latency)
- **`@repo/logger`**: Structured logging for Prometheus/Grafana health checks

### Patterns to Reuse
- **VPC networking**: Same VPC as ElastiCache and Lambda (private subnets)
- **Security groups**: Prometheus/Grafana in private subnets, VPN-only access
- **Cost monitoring**: CloudWatch billing alarms, Cost Explorer tagging (similar to WISH-2124)
- **Fargate deployment**: Similar to other containerized services in the platform

### Monitoring Patterns to Reuse
- **CloudWatch metric namespace**: `Lego/FeatureFlags` namespace from WISH-2124
- **Alert patterns**: Slack integration similar to existing application alerts

## Architecture Notes

### System Architecture

```
┌─────────────────────┐
│ AWS CloudWatch      │
│ (ElastiCache metrics)│
└──────────┬──────────┘
           │ AWS API
           ▼
┌─────────────────────┐
│ CloudWatch Exporter │ (Fargate sidecar)
│ Port 9106           │
└──────────┬──────────┘
           │ HTTP scrape (1 min)
           ▼
┌─────────────────────┐
│ Prometheus Server   │ (Fargate/EC2)
│ - 90-day retention  │
│ - PromQL queries    │
└──────────┬──────────┘
           │ Data source
           ▼
┌─────────────────────┐
│ Grafana Server      │ (Fargate/EC2)
│ - Dashboards        │
│ - Alerting          │
│ - SSO auth          │
└─────────────────────┘
           │ VPN-only access
           ▼
┌─────────────────────┐
│ Engineering Team    │
└─────────────────────┘
```

### Data Flow

1. **Metric Emission**: WISH-2124 emits CloudWatch metrics (`cache_hit_rate`, etc.) from Lambda
2. **CloudWatch Storage**: AWS CloudWatch stores metrics (15-day detailed retention)
3. **Prometheus Scraping**: CloudWatch Exporter scrapes CloudWatch API every 1 minute, converts to Prometheus format
4. **Long-Term Storage**: Prometheus stores metrics locally (90-day retention, EBS-backed)
5. **Visualization**: Grafana queries Prometheus via PromQL, renders dashboards
6. **Alerting**: Grafana evaluates alert rules, sends Slack notifications on threshold breaches

### Deployment Architecture

**Option A: AWS Fargate (Recommended for MVP)**
- **Pros**: Serverless, auto-scaling, no server management
- **Cons**: Higher cost (~$40-80/month vs. $20-40 for EC2)
- **Use Case**: Small team, low operational overhead, pay-for-use

**Option B: EC2 t3.small**
- **Pros**: Lower cost, full control, persistent storage
- **Cons**: Manual scaling, server patching, higher operational burden
- **Use Case**: Cost-sensitive, dedicated ops team

**MVP Recommendation**: Start with Fargate for simplicity, migrate to EC2 if costs exceed budget.

### Security Architecture

**Network Security:**
- Prometheus/Grafana in private VPC subnets (no internet gateway)
- VPN-only access to Grafana UI (AWS Client VPN or third-party VPN)
- Security groups: Allow inbound HTTPS (443) from VPN CIDR only

**Authentication:**
- Grafana SSO via AWS Cognito (or basic auth for MVP)
- IAM role for CloudWatch Exporter (no hardcoded credentials)
- Prometheus UI read-only (no public write access)

**Data Security:**
- Metrics contain no PII (cache hit rates, latency, connection counts)
- Dashboard access restricted to engineering team
- Grafana database (RDS) encrypted at rest

## Test Plan

See `_pm/TEST-PLAN.md` for comprehensive test plan including:
- Happy path tests (5 tests)
- Error cases (4 tests)
- Edge cases (3 tests)
- Infrastructure validation (dashboard access, metric scraping, alerting)
- Success criteria and rollback plan

## UI/UX Notes

See `_pm/UIUX-NOTES.md` - **SKIPPED** (internal monitoring dashboard, no end-user UI)

## Dev Feasibility Review

See `_pm/DEV-FEASIBILITY.md` for detailed feasibility analysis including:
- MVP-critical risks (4 risks identified)
- Missing requirements (3 decisions needed)
- Change surface analysis
- MVP evidence expectations
- Confidence: Medium

## Risks & Mitigations

### Risk 1: CloudWatch API Rate Limiting
**Likelihood**: Medium
**Impact**: Medium (gaps in metric collection)

**Mitigation:**
- CloudWatch Exporter scrapes at 1-minute intervals (well below API limits)
- Request batching: Fetch multiple metrics in single API call
- Exponential backoff on rate limit errors (CloudWatch Exporter built-in)
- Monitor CloudWatch API usage via CloudWatch metrics (meta-monitoring)

### Risk 2: Prometheus Storage Exhaustion
**Likelihood**: Low
**Impact**: High (metric loss if storage full)

**Mitigation:**
- Provision 50 GB EBS volume (supports ~100 days of MVP metrics)
- CloudWatch alarm at 80% storage utilization
- Automated retention cleanup (90-day TTL enforced)
- Monitor storage growth rate, right-size volume if needed

### Risk 3: Grafana Dashboard Complexity
**Likelihood**: Medium
**Impact**: Low (team finds dashboard confusing)

**Mitigation:**
- Start with 6 essential panels (cache hit rate, latency, errors, connections, memory, network)
- Use pre-built Grafana templates from community (Redis monitoring templates)
- Document dashboard usage in `docs/infrastructure/grafana-usage.md`
- Iterate based on team feedback (avoid over-engineering)

### Risk 4: Infrastructure Cost Overruns
**Likelihood**: Low
**Impact**: Medium (unexpected AWS bills)

**Mitigation:**
- CloudWatch billing alarm at $100/month threshold
- Start with Fargate spot instances for cost savings (30-70% discount)
- Monitor Cost Explorer monthly, right-size instances if underutilized
- Document cost benchmarks: $40-80/month expected for MVP workload

## Deployment Strategy

### Phase 1: Local Development Setup (Week 1)
1. Run Prometheus/Grafana locally via Docker Compose
2. Configure CloudWatch Exporter with AWS credentials (local testing)
3. Create initial dashboard JSON with sample metrics
4. Test dashboard visualization and alerting

### Phase 2: Staging Deployment (Week 1-2)
1. Deploy Prometheus/Grafana to staging VPC (Fargate)
2. Configure CloudWatch Exporter IAM role
3. Import dashboard JSON to staging Grafana
4. Test end-to-end metric flow (CloudWatch → Prometheus → Grafana)
5. Validate alerting (trigger test alerts, verify Slack notifications)

### Phase 3: Production Deployment (Week 2)
1. Deploy to production VPC
2. Configure VPN-only access
3. Set up AWS SSO authentication
4. Import production dashboard
5. Monitor for 48 hours, validate metric accuracy

### Phase 4: Post-Deployment Validation (Week 2-3)
1. Compare Prometheus metrics with CloudWatch (validate accuracy)
2. Verify 90-day retention (wait for initial 90-day period)
3. Cost validation: Confirm Cost Explorer shows expected charges
4. Team training: Dashboard usage session for engineering team

## Related Stories

**Dependencies:**
- **WISH-2124**: Redis infrastructure (provides CloudWatch metrics to visualize)

**Potential Follow-ups:**
- **WISH-XXXX**: Multi-region dashboard aggregation (global cache observability)
- **WISH-XXXX**: Custom Prometheus exporter for Redis (direct scraping, sub-minute granularity)
- **WISH-XXXX**: ML-based anomaly detection (predictive alerting)
- **WISH-XXXX**: Business user dashboards (stakeholder cache performance reports)

## Definition of Done

- [ ] All 10 acceptance criteria pass
- [ ] Prometheus server deployed and scraping CloudWatch metrics
- [ ] Grafana dashboard displays all 6 metric panels with live data
- [ ] Alert rules configured and tested (Slack notifications working)
- [ ] 90-day retention validated (storage monitoring in place)
- [ ] VPN-only access enforced (public access blocked)
- [ ] Dashboard JSON committed to repository
- [ ] Cost monitoring configured (billing alarm, Cost Explorer tags)
- [ ] Documentation complete (dashboard usage, cost benchmarks, disaster recovery)
- [ ] Team training session completed
- [ ] TypeScript compilation passes (if any supporting code)
- [ ] ESLint passes with no errors
- [ ] Infrastructure code review approved

## Token Budget

### Phase Summary

| Phase | Estimated | Actual | Delta | Notes |
|-------|-----------|--------|-------|-------|
| Story Generation | ~12k | — | — | Follow-up from WISH-2124 |
| Elaboration | ~10k | — | — | Monitoring infrastructure story |
| Implementation | ~12k | — | — | Infrastructure + Dashboard + Testing |
| Code Review | ~4k | — | — | Monitoring changes |
| **Total** | ~38k | — | — | Medium-sized monitoring story |

## Agent Log

| Timestamp (America/Denver) | Agent | Action | Outputs |
|---|---|---|---|
| 2026-01-30 00:00 | pm-story-followup-leader | Created follow-up from WISH-2124 finding #4 | WISH-20350.md (initial draft) |

---

## QA Discovery Notes (for PM Review)

_To be added by QA Elaboration_

### Gaps Identified

_None yet - story awaiting elaboration_

### Enhancement Opportunities

_None yet - story awaiting elaboration_

### Follow-up Stories Suggested

_None yet - story awaiting elaboration_

### Items Marked Out-of-Scope

_None yet - story awaiting elaboration_
