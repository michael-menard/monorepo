---
status: backlog
split_from: STORY-01712
split_part: 2 of 4
---

# STORY-01722: Session & File Management - Upload Enhancements

## Split Context

This story is part of a split from STORY-01712.
- **Original Story:** STORY-01712 (Session & File Management - Advanced Features, which itself was split from STORY-0171)
- **Split Reason:** STORY-01712 elaboration identified 16 ACs (8 gap remediations + 8 enhancements) that exceeded safe story sizing boundaries. This split addresses 3 high-value upload UX enhancements that improve developer experience with the session management API.
- **This Part:** 2 of 4 (Z=2)
- **Dependency:** STORY-01721 (requires gap remediations to be complete before adding enhancements)

## Title

Multipart Upload Session Management - Upload Enhancements

## Context

This story implements 3 high-value features that significantly improve the developer experience with the multipart upload session management API:

1. **Presigned URL Batch Generation** - Instead of requiring clients to make N separate requests to upload N parts, the register file endpoint can return all presigned URLs upfront, reducing round trips and simplifying client logic.

2. **Batch File Registration** - Clients can register multiple files in a single API call instead of making N requests for N files. Supports partial success (some files succeed, others fail with specific error messages).

3. **Upload Resume Capability** - If an upload is interrupted, clients can query which parts were successfully uploaded and resume from where they left off, rather than starting over. Requires storing part ETags in the database.

These features build on the completed gap remediations from STORY-01721 and are independent of analytics, duplicate detection, and WebSocket features (STORY-01723, STORY-01724).

## Goal

Add developer-friendly enhancements to the session management API that reduce network round trips, enable batch operations, and support upload resume for interrupted transfers. All changes are additive and maintain full API compatibility with existing clients that don't use these features.

## Non-Goals

- Analytics tracking (STORY-01723)
- Duplicate file detection (STORY-01723)
- Automatic session extension (STORY-01723)
- TypeScript SDK generation (STORY-01723)
- WebSocket progress tracking (STORY-01724)
- Database schema changes beyond storing part ETags
- Binary part upload handling (STORY-0172)
- Session finalization (STORY-0172)
- Background cleanup jobs (STORY-018)

## Scope

### Upload Enhancements (3 items)

1. **Presigned URL Batch Generation** (AC-19) - Register file endpoint accepts `partCount` and returns array of presigned URLs for all parts
2. **Batch File Registration** (AC-24) - New `POST /sessions/:id/files/batch` endpoint for registering multiple files at once
3. **Upload Resume Capability** (AC-25) - Store part ETags, add `GET /sessions/:id/files/:fileId/parts` endpoint to query uploaded parts

### Packages/Apps Affected

**Modify:**
- `apps/api/platforms/vercel/api/mocs/uploads/sessions/[sessionId]/files/index.ts` (add presigned URL batch generation)
- `apps/api/platforms/vercel/api/mocs/uploads/sessions/[sessionId]/files/[fileId]/complete.ts` (validate all parts present before S3 complete)
- `apps/api/platforms/vercel/vercel.json` (add routes for batch and parts endpoints)

**Create:**
- `apps/api/platforms/vercel/api/mocs/uploads/sessions/[sessionId]/files/batch.ts` (batch registration endpoint)
- `apps/api/platforms/vercel/api/mocs/uploads/sessions/[sessionId]/files/[fileId]/parts.ts` (query parts endpoint)
- `__http__/story-01722-upload-enhancements.http` (test file for new features)

**Database:**
- Add `upload_session_parts` table to store part ETags (or extend existing table)

## Acceptance Criteria

### AC-19: Presigned URL Batch Generation
- [ ] Register file endpoint accepts optional `partCount` in request body
- [ ] When `partCount` provided, response includes `presignedUrls: [{ partNumber, url, expiresAt }]` array
- [ ] Presigned URLs valid for 15 minutes (configurable via env var `PRESIGNED_URL_TTL_MINUTES`)
- [ ] Include part size and upload headers (Content-Type, Content-Length) in presigned URL metadata
- [ ] Document trade-off: large sessions create large response payloads
- [ ] If `partCount` not provided, maintain existing behavior (no presigned URLs)

### AC-24: Batch File Registration
- [ ] Add `POST /api/mocs/uploads/sessions/:sessionId/files/batch` endpoint
- [ ] Accepts array of file metadata: `{ files: FileMetadata[] }`
- [ ] Returns array of results: `{ results: [{ fileId, uploadId, presignedUrls?, error? }] }`
- [ ] Partial success supported: some files may succeed while others fail
- [ ] Each failure includes specific error code and message (e.g., file count exceeded, duplicate key)
- [ ] Document error handling strategy for partial failures (no rollback - partial commit)
- [ ] Successful registrations are committed even if later files in batch fail

### AC-25: Upload Resume Capability
- [ ] Create `upload_session_parts` table with columns: `(session_id, file_id, part_number, etag, uploaded_at)`
- [ ] Store uploaded part ETags as parts are uploaded (triggered on part upload complete)
- [ ] Add `GET /api/mocs/uploads/sessions/:sessionId/files/:fileId/parts` endpoint
- [ ] Returns: `{ parts: [{ partNumber, etag, uploadedAt }] }`
- [ ] Client can query uploaded parts and skip re-uploading them on resume
- [ ] Complete endpoint validates all parts present before calling S3 CompleteMultipartUpload
- [ ] Document resume flow: query parts → upload missing parts → complete

## Reuse Plan

### Existing Packages to Use

| Package | Purpose |
|---------|---------|
| `@repo/logger` | Structured logging for batch operations |
| Core handlers from STORY-01711 | Base implementation to extend |
| Core handlers from STORY-01721 | Gap remediations (idempotency, expiration handling) |

### Existing Core Code to Reference

| Path | Purpose |
|------|---------|
| STORY-01711 handlers | Base implementation |
| STORY-01721 handlers | Extended error handling |
| `apps/api/core/config/upload.ts` | Upload configuration |
| `apps/api/platforms/aws/endpoints/moc-uploads/` | AWS implementation patterns for presigned URLs |

### New Shared Code

No new shared packages. Extensions are inline in Vercel handlers. Part storage is local to this feature.

## Architecture Notes (Ports & Adapters)

### Port Interfaces (Extended)

**File Service Port (Extended):**
- `registerFile(sessionId, fileMetadata, partCount?) -> { fileId, uploadId, presignedUrls? }`
- `batchRegisterFiles(sessionId, files) -> { results: [] }`
- `getUploadedParts(fileId) -> { parts: [{partNumber, etag}] }`
- `storePartETag(fileId, partNumber, etag) -> void`

### Adapter Responsibilities

**Database Adapter (Drizzle) - Extended:**
- Insert/update `upload_session_parts` table
- Query parts by file ID for resume endpoint
- Batch insert for batch registration (use transaction)

**S3 Adapter - Extended:**
- Generate multiple presigned URLs in batch (S3 SDK `getSignedUrl` called N times)
- List uploaded parts for validation (S3 `listParts` API)
- Validate part ETags match before calling CompleteMultipartUpload

## Required Vercel / Infra Notes

### Route Rewrites (Additional)

```json
// vercel.json (rewrites section - add to existing)
[
  {
    "source": "/api/mocs/uploads/sessions/:sessionId/files/batch",
    "destination": "/api/mocs/uploads/sessions/[sessionId]/files/batch"
  },
  {
    "source": "/api/mocs/uploads/sessions/:sessionId/files/:fileId/parts",
    "destination": "/api/mocs/uploads/sessions/[sessionId]/files/[fileId]/parts"
  }
]
```

### Environment Variables Required (Additional)

- `PRESIGNED_URL_TTL_MINUTES` - TTL for presigned URLs (default: 15)
- `MAX_BATCH_SIZE` - Maximum files per batch request (default: 10, prevents abuse)

### Database Migration

**New Table: `upload_session_parts`**

```sql
CREATE TABLE upload_session_parts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  session_id UUID NOT NULL REFERENCES upload_sessions(id) ON DELETE CASCADE,
  file_id UUID NOT NULL REFERENCES upload_session_files(id) ON DELETE CASCADE,
  part_number INT NOT NULL,
  etag VARCHAR(255) NOT NULL,
  uploaded_at TIMESTAMP NOT NULL DEFAULT NOW(),
  UNIQUE (file_id, part_number)
);

CREATE INDEX idx_upload_session_parts_file_id ON upload_session_parts(file_id);
CREATE INDEX idx_upload_session_parts_session_id ON upload_session_parts(session_id);
```

## HTTP Contract Plan

### Required `.http` Requests

All requests are defined in `__http__/story-01722-upload-enhancements.http`:

| Request | Test ID | Description |
|---------|---------|-------------|
| `registerFileWithPresignedUrls` | PU-HP-001 | Register file with partCount=5, receive 5 presigned URLs |
| `batchRegisterFiles` | BR-HP-001 | Batch register 3 files, all succeed |
| `batchRegisterFilesPartialFailure` | BR-HP-002 | Batch register 3 files, 1 fails (file count exceeded) |
| `getUploadedParts` | UR-HP-001 | Query uploaded parts for resume |
| `completeFileWithPartsValidation` | UR-HP-002 | Complete file after all parts uploaded |

### Error Case Requests

| Request | Test ID | Expected Status |
|---------|---------|-----------------|
| Batch too large | BR-ERR-001 | 400 (exceeds MAX_BATCH_SIZE) |
| Presigned URL expired | PU-ERR-001 | Client receives 403 from S3 |
| Complete with missing parts | UR-ERR-001 | 400 (not all parts uploaded) |

### Required Evidence

Captured in proof document:
- All happy path requests with responses
- Batch partial failure example with specific error messages
- Database queries showing `upload_session_parts` data
- Presigned URL structure example
- Resume flow: query parts → upload missing → complete

## Seed Requirements

### Test Data for Upload Enhancements

```sql
-- Session for batch testing
INSERT INTO upload_sessions (id, user_id, status, part_size_bytes, metadata, expires_at, created_at, updated_at)
VALUES (
  'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee',
  'dev-user-00000000-0000-0000-0000-000000000001',
  'active',
  5242880,
  '{"maxFiles": 5}',
  NOW() + INTERVAL '30 minutes',
  NOW(),
  NOW()
);

-- File with partial upload for resume testing
INSERT INTO upload_session_files (id, session_id, file_key, file_size_bytes, status, upload_id, created_at, updated_at)
VALUES (
  'ffffffff-ffff-ffff-ffff-ffffffffffff',
  'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee',
  'resume-test.pdf',
  10485760, -- 10MB = 2 parts
  'pending',
  's3-upload-id-12345',
  NOW(),
  NOW()
);

-- Parts already uploaded (1 of 2)
INSERT INTO upload_session_parts (id, session_id, file_id, part_number, etag, uploaded_at)
VALUES (
  '11111111-1111-1111-1111-111111111111',
  'eeeeeeee-eeee-eeee-eeee-eeeeeeeeeeee',
  'ffffffff-ffff-ffff-ffff-ffffffffffff',
  1,
  'etag-part-1',
  NOW()
);
```

### Seed Location

Add to `apps/api/core/database/seeds/story-01722.ts` and register in seed index.

## Test Plan (Happy Path / Error Cases / Edge Cases)

### Happy Path Tests

| Feature | Test ID | Description | Expected |
|---------|---------|-------------|----------|
| Presigned URLs | PU-HP-001 | Register file with partCount=5 | 201 with 5 presigned URLs |
| Batch Registration | BR-HP-001 | Batch register 3 files | 201 with 3 success results |
| Upload Resume | UR-HP-001 | Query uploaded parts | 200 with parts array |
| Complete with Parts | UR-HP-002 | Complete after all parts uploaded | 200 with file URL |

### Error Cases

| Category | Test ID | Condition | Status | Code |
|----------|---------|-----------|--------|------|
| Batch Size | BR-ERR-001 | Batch exceeds max size | 400 | BAD_REQUEST |
| Presigned URL | PU-ERR-001 | Client uses expired URL | 403 | Forbidden (from S3) |
| Resume | UR-ERR-001 | Complete with missing parts | 400 | BAD_REQUEST |

### Edge Cases

- **Partial batch success**: Some files succeed, others fail. No rollback.
- **Presigned URL expiration**: URLs expire after 15 minutes. Client must handle S3 403.
- **Resume with no parts**: Empty array returned, client uploads all parts.
- **Resume with duplicate parts**: If client re-uploads part, ETag updated (last write wins).

### Evidence Requirements

Per-feature proof:
- [ ] Happy path request/response for each AC
- [ ] Error case examples (batch size, missing parts)
- [ ] Database state showing `upload_session_parts` data
- [ ] Presigned URL array example (structure, headers, TTL)
- [ ] Resume flow demonstration

---

## Risks / Edge Cases

### Risks

1. **Presigned URL Payload Size:** For large files with many parts (e.g., 1GB file = 200 parts), response payload could be 50-100KB. Document limits and consider pagination if needed.
2. **Batch Partial Failure Complexity:** Clients must handle partial success. Some files registered, others failed. No transaction rollback - committed files stay registered.
3. **Resume Race Condition:** Two clients could resume same upload simultaneously. Last ETag write wins. Document that clients should coordinate.
4. **Part Validation Performance:** Complete endpoint must validate all parts present. For large files (200+ parts), query performance matters. Index on `file_id` required.
5. **S3 ListParts Consistency:** S3 `listParts` is eventually consistent. Parts uploaded seconds ago might not appear immediately. Add retry logic if complete fails with "missing parts".

### Edge Cases

- **Batch registration transaction boundary**: Each file registration is atomic, but batch is not. Partial commit on failures.
- **Presigned URL regeneration**: If client loses URLs, they can call register again with same fileId (idempotent) to get new URLs.
- **Resume with zero parts**: Valid case - file registered but no parts uploaded yet.
- **Complete with extra parts**: If more parts uploaded than expected, ignore extras (S3 behavior).

---

## Token Budget

| Phase | Agent | Input (est) | Output (est) |
|-------|-------|-------------|--------------|
| PM: Story Split | PM Split Leader | ~20K | ~8K |
| **PM Total** | — | **~20K** | **~8K** |

---

## Agent Log

| Timestamp (America/Denver) | Agent | Action | Outputs |
|---|---|---|---|
| 2026-01-25 | PM Split Leader | Split STORY-01712 into 4 stories (STORY-01721, STORY-01722, STORY-01723, STORY-01724) | `plans/stories/backlog/STORY-01722/STORY-01722.md` |
