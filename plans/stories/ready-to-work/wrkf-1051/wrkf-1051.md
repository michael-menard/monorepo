---
story_id: wrkf-1051
title: elab_graph MVP (Core Implementation)
status: ready-to-work
created: 2026-01-27
updated: 2026-01-27
epic: wrkf
feature: LangGraph Orchestrator - Story Elaboration Workflow (MVP)
depends_on: []
split_from: wrkf-1050
split_part: 1 of 4
related_stories:
  - wrkf-1010 # GraphState Schema
  - wrkf-1020 # Node Runner Infrastructure
  - wrkf-1041 # pm_generate_graph Subgraph - Core Infrastructure (reference implementation)
  - wrkf-1120 # MCP Read Tools (optional dependency)
---

# wrkf-1051: elab_graph MVP (Core Implementation)

## Split Context

This story is part of a split from wrkf-1050.
- **Original Story:** wrkf-1050 (elab_graph Subgraph)
- **Split Reason:** QA Elaboration identified 26 AC (original 8 + 18 additions from gap/enhancement analysis), exceeding the 8-10 AC threshold. Split into 4 focused stories to maintain implementation quality.
- **This Part:** 1 of 4 (MVP - Core Implementation)
- **Dependency:** No dependencies - this is the foundational story that enables the other 3 splits

**Sibling Stories:**
- wrkf-1052: elab_graph Observability & Quality (depends on wrkf-1051)
- wrkf-1053: elab_graph Advanced Features (depends on wrkf-1051)
- wrkf-1054: elab_graph Metadata & Linking (depends on wrkf-1051)

## Context

The LangGraph orchestrator requires a subgraph to automate the elaboration of story documents before implementation. Currently, the `/elab-story` command relies on manual or ad-hoc elaboration creation, which is time-consuming and inconsistent. This story implements the **MVP version** of the `elab_graph` subgraph to orchestrate story elaboration using LangGraph nodes, leveraging existing infrastructure from wrkf-1010 (GraphState) and wrkf-1020 (Node Runner).

This MVP focuses on the **core elaboration generation pipeline** with essential quality gates:
1. Read a story document and extract its content (title, context, goal, scope, acceptance criteria)
2. Explore the codebase to gather relevant context (package structure, types, existing patterns, test examples)
3. Use an LLM (Claude) to generate detailed elaboration content with implementation guidance
4. Validate that the elaboration addresses all acceptance criteria from the story
5. Track costs (LLM token usage) and quality metrics for observability

This is a critical building block for the orchestrator ecosystem, establishing patterns for codebase exploration and context-aware LLM generation that will be reused in other subgraphs (dev implementation, code review, etc.).

## Goal

Implement the **MVP version** of the `elab_graph` LangGraph subgraph to automatically generate complete, high-quality elaboration documents from story files, with codebase context integration, acceptance criteria validation, cost tracking, and essential quality gates to ensure implementation readiness.

**Success Criteria:**
- Elaboration generation completes end-to-end without manual intervention
- Generated elaborations include concrete implementation guidance based on actual codebase patterns
- Subgraph integrates cleanly with existing GraphState and Node Runner infrastructure
- AC validator confirms all acceptance criteria are addressed in elaboration
- Elaboration quality is sufficient for developer implementation (actionable, specific, references actual code)
- LLM costs are tracked and logged for monitoring
- Minimum context requirements prevent low-quality elaborations

## Non-goals

- Multi-turn elaboration refinement (covered in wrkf-1052 - Observability & Quality)
- Human-in-the-loop approval before writing elaboration file (manual PM review happens post-generation)
- Elaboration versioning or diff tracking (covered in wrkf-1054 - Metadata & Linking)
- Integration with CI/CD for automated elaboration generation (invoked manually via CLI only)
- Advanced quality validation beyond AC coverage (e.g., implementation feasibility assessment, quality scoring - covered in wrkf-1052)
- Codebase indexing or caching layer (covered in wrkf-1053 - Advanced Features)
- Visual elaboration (diagrams, flowcharts) - markdown text only
- Git history analysis (codebase explorer reads current state only)
- Integration with external documentation (no fetching from external URLs or knowledge bases)
- Parallel codebase exploration (covered in wrkf-1053 - Advanced Features)
- Embeddings-based context selection (covered in wrkf-1053 - Advanced Features)
- Semantic AC validation with LLM (covered in wrkf-1053 - Advanced Features)
- Interactive refinement (covered in wrkf-1052 - Observability & Quality)
- Dry-run mode (covered in wrkf-1052 - Observability & Quality)
- Elaboration quality scoring (covered in wrkf-1052 - Observability & Quality)

## Scope

### Packages Affected

**Primary:**
- `packages/backend/orchestrator/src/subgraphs/elab-graph/` (new directory)
  - `index.ts` - Subgraph entry point and graph definition
  - `nodes/story-reader.ts` - Node to read and parse story file
  - `nodes/codebase-explorer.ts` - Node to gather codebase context from relevant packages
  - `nodes/elaboration-writer.ts` - LLM node to generate elaboration content via Claude API
  - `nodes/ac-validator.ts` - Node to validate AC coverage in elaboration
  - `graph.ts` - LangGraph composition and edge definitions
  - `__tests__/` - Unit and integration tests for all nodes and graph

**Supporting:**
- `packages/backend/orchestrator/src/core/state/graph-state.ts` (extend with elaboration fields)
- `packages/backend/orchestrator/src/utils/` (file I/O, markdown parsing utilities - may reuse from wrkf-1041)
- `packages/backend/orchestrator/templates/elaboration-template.md` (new file - elaboration template)
- `packages/backend/orchestrator/src/clients/claude-client.ts` (reuse from wrkf-1041 if exists, or create)

**Adjacent:**
- `.claude/commands/elab-story.md` - Command documentation (may require updates to reference new subgraph)

### Endpoints

**None** - This is backend infrastructure, not HTTP API.

The subgraph is invoked via the `/elab-story` CLI command, not via HTTP endpoints.

### Data/Storage

**Reads:**
- Story file (e.g., `plans/stories/wrkf/wrkf-1051/wrkf-1051.md`)
- Codebase files from packages listed in story scope (e.g., `packages/backend/orchestrator/src/**/*.ts`)
- Elaboration template file (`packages/backend/orchestrator/templates/elaboration-template.md`)

**Writes:**
- Elaboration document (e.g., `plans/stories/wrkf/wrkf-1051/ELAB-wrkf-1051.md`)

**No database access** - all I/O is filesystem-based.

## Acceptance Criteria

### AC1: Story Reader Node Loads Story Content
**Given** a story file exists at `{FEATURE_DIR}/{STORY_ID}/{STORY_ID}.md`
**And** the story file contains valid YAML frontmatter and required sections
**When** the story reader node executes
**Then** the story content is parsed and loaded into GraphState
**And** GraphState contains `storyContent` with fields: `title`, `context`, `goal`, `scope`, `acceptanceCriteria`
**And** story frontmatter is parsed correctly (story_id, status, dependencies)
**And** no file read errors occur

**Validation:**
- Unit test verifies story reader parses valid story file correctly
- Integration test confirms GraphState contains story content after node execution
- Error handling test: missing story file returns clear error in GraphState
- Error handling test: malformed YAML frontmatter returns parse error with actionable message

### AC2: Codebase Explorer Node Gathers Relevant Context
**Given** GraphState contains story content with scope (packages affected)
**And** relevant packages exist in monorepo (e.g., `packages/backend/orchestrator`)
**When** the codebase explorer node executes
**Then** the node reads relevant files from packages listed in story scope
**And** GraphState contains `codebaseContext` with fields: `filePaths`, `typeDefinitions`, `testPatterns`
**And** codebase context includes package structure and existing patterns
**And** context size does not exceed 100KB total (configurable limit)
**And** file exploration completes within 30 seconds (timeout)

**Validation:**
- Unit test verifies codebase explorer reads files from specified packages
- Integration test confirms GraphState includes codebase context (file paths, type samples)
- Performance test: large package scope (5+ packages) completes within timeout
- Context size test: context does not exceed 100KB limit
- Error handling test: package not found logs warning and continues with available context

**Codebase Explorer Behavior:**
- Reads files matching: `src/**/*.ts`, `src/**/*.tsx`
- Skips: `node_modules/`, `dist/`, `__tests__/` (unless test patterns explicitly requested), `.next/`, `build/`
- Skips files larger than 500KB (configurable limit)
- Logs: files explored (paths, sizes), context size metrics, exploration duration

### AC3: Elaboration Writer Node Generates Complete Elaboration via LLM
**Given** GraphState contains story content and codebase context
**When** the elaboration writer node executes (LLM call to Claude)
**Then** a complete elaboration document is generated with all required sections
**And** the elaboration includes concrete implementation guidance referencing actual codebase patterns
**And** GraphState contains `generatedElaborationContent` field with markdown output
**And** no placeholder text in critical sections (e.g., "TBD", "TODO")

**Validation:**
- Integration test with mocked LLM client produces expected elaboration structure
- Manual test with real Claude API generates quality elaboration (reviewed by PM)
- Error handling test: LLM failure returns error in GraphState (no partial file written)
- Content quality test: elaboration references actual file paths and types from codebase context

**LLM Configuration:**
- Model: `claude-sonnet-4-5` (cost-effective for elaboration generation)
- Temperature: 0.3 (balance creativity with consistency)
- Max tokens: 16000 (sufficient for detailed elaborations)
- Retry on transient errors (rate limit, 5xx) up to 3 times with exponential backoff (1s, 2s, 4s)

**Required Elaboration Sections:**
- Scope (packages, files affected - specific paths)
- Implementation Plan (step-by-step guidance with concrete actions)
- Technical Approach (architecture, patterns, integration points)
- AC Breakdown (each AC with specific implementation notes)
- Reuse Plan (existing utilities, packages to leverage)
- Test Strategy (how to test each AC - unit, integration, E2E)

### AC4: AC Validator Node Checks Elaboration Coverage
**Given** a generated elaboration in GraphState
**When** the AC validator node executes
**Then** the validator checks that all acceptance criteria from story are addressed in elaboration
**And** validation results are added to GraphState (`validationResults` with `isValid`, `coveredACs`, `missingACs`)
**And** if any ACs are not addressed, validation fails with list of missing ACs
**And** if validation fails, the graph halts with actionable error messages (e.g., "Missing coverage for AC3: Elaboration Writer...")

**Validation:**
- Unit test verifies validator detects missing AC coverage
- Unit test verifies validator accepts complete elaboration with all ACs addressed
- Integration test confirms graph halts gracefully on validation failure
- Coverage report test: validator outputs list of covered vs missing ACs

**AC Validator Behavior:**
- Uses keyword matching + section header analysis (not semantic LLM validation)
- Checks for AC ID (e.g., "AC1", "AC2") or AC text in elaboration
- Outputs coverage report: which ACs addressed, which missing, coverage percentage
- Validation failure halts graph with actionable error

### AC5: Elaboration File Written to Correct Output Path
**Given** a validated elaboration in GraphState
**When** the validation node passes
**Then** the elaboration is written to `{FEATURE_DIR}/{STORY_ID}/ELAB-{STORY_ID}.md` (e.g., `plans/stories/wrkf/wrkf-1051/ELAB-wrkf-1051.md`)
**And** the file write is atomic (write to temp file, rename on success)
**And** no partial or corrupted files are left on disk if write fails

**Validation:**
- Integration test verifies elaboration file exists at expected path after graph completion
- Error handling test: write failure (permissions, disk full) returns error in GraphState without partial file
- Edge case test: existing elaboration file causes graph to fail with "Elaboration already exists" error (prevent accidental overwrites)

### AC6: GraphState Extensions for Elaboration Generation
**Given** the base GraphState schema from wrkf-1010
**When** this subgraph extends GraphState
**Then** the following fields are added (Zod schema):
- `storyContent`: object with `title: string`, `context: string`, `goal: string`, `scope: string`, `acceptanceCriteria: string[]`
- `codebaseContext`: object with `filePaths: string[]`, `typeDefinitions: string`, `testPatterns: string`
- `generatedElaborationContent`: string (markdown output from writer node)
- `validationResults`: object with `isValid: boolean`, `coveredACs: string[]`, `missingACs: string[]`, `coveragePercentage: number`

**Validation:**
- Unit test verifies Zod schema validation for new fields
- Type-checking passes (no TypeScript errors on GraphState usage)

### AC7: Error Handling and Fail-Fast Strategy
**Given** any node in the subgraph encounters an error
**When** the error occurs (file not found, LLM failure, validation failure)
**Then** the graph halts immediately (fail-fast)
**And** errors are logged via `@repo/logger` at ERROR level
**And** GraphState contains error details in `errors` array
**And** no downstream nodes execute after error

**Validation:**
- Error handling tests for each error scenario:
  - Story file not found
  - Story file missing required sections (e.g., "Acceptance Criteria")
  - Codebase explorer cannot access package (logs warning, continues)
  - Output directory creation fails
  - LLM API error (timeout, rate limit, 5xx)
  - Validation failure (missing AC coverage)
- Integration test confirms graph halts on first fatal error
- Logs include actionable error messages (file paths, error types, suggested fixes)

**Error Handling Philosophy:**
- Fail-fast for fatal errors (story not found, LLM failure, write failure)
- Graceful degradation for codebase explorer (log warning, continue with partial context if some files unreadable)
- Validation failure halts graph (elaboration not written)

### AC8: Integration with Node Runner Infrastructure (wrkf-1020)
**Given** the Node Runner infrastructure from wrkf-1020 provides node factory, error handling, and logging
**When** nodes in this subgraph are created
**Then** they use the node factory pattern from wrkf-1020 (`createNode()`)
**And** error handling and retry logic (for LLM calls) leverage wrkf-1020 infrastructure
**And** all node executions are logged via `@repo/logger`

**Validation:**
- Code review confirms nodes use `createNode()` factory
- Integration test logs show node execution lifecycle (start, complete, error)

### AC9: LLM Cost Tracking
**Given** the elaboration writer node calls Claude API
**When** the LLM response is received
**Then** input and output token counts are extracted from the Claude API response
**And** token counts are logged to GraphState in a `metrics` field
**And** token counts are logged via `@repo/logger` at INFO level for cost monitoring

**Validation:**
- Unit test verifies token counts are extracted from mocked Claude API responses
- Integration test confirms token metrics appear in GraphState after elaboration generation
- Logs show token counts in format: `Elaboration generation: input_tokens=X, output_tokens=Y, total_tokens=Z`

**Metrics Schema:**
```typescript
metrics: {
  llmUsage: {
    inputTokens: number,
    outputTokens: number,
    totalTokens: number,
    model: string,
  }
}
```

### AC10: Elaboration Quality Metrics
**Given** elaboration generation completes successfully
**When** the AC validator runs
**Then** the following quality metrics are captured and added to GraphState:
- `sectionsCount`: number of sections in elaboration
- `acCoveragePercentage`: percentage of ACs covered (from AC validator)
- `contextSize`: total size of codebase context in bytes
- `llmLatencyMs`: time taken for LLM call in milliseconds
- `generatedAt`: ISO 8601 timestamp of generation

**Validation:**
- Unit test verifies quality metrics are populated in GraphState
- Integration test confirms all metrics are present after successful generation
- Logs include quality metrics summary

**Metrics Schema:**
```typescript
qualityMetrics: {
  sectionsCount: number,
  acCoveragePercentage: number,
  contextSizeBytes: number,
  llmLatencyMs: number,
  generatedAt: string, // ISO 8601
}
```

### AC11: Minimum Context Requirements
**Given** the codebase explorer runs
**When** context gathering completes
**Then** the graph validates minimum context requirements are met:
- At least 3 packages readable OR
- At least 5 total files readable
**And** if minimum context not met, the graph fails with clear error "Insufficient context: <details>"
**And** the error message includes what was found and what is required

**Validation:**
- Unit test: codebase explorer with only 2 packages readable fails validation
- Unit test: codebase explorer with only 3 files readable fails validation
- Unit test: codebase explorer with 3 packages OR 5 files passes validation
- Error message includes: "Found X packages, Y files. Required: 3 packages OR 5 files."

### AC12: Story with No Scope Section Edge Case
**Given** a story file exists but is missing the "Scope" section
**When** the story reader node parses the file
**Then** the node fails immediately with error "Story missing required 'Scope' section"
**And** the error message is actionable (suggests adding Scope section to story file)
**And** no elaboration generation is attempted

**Validation:**
- Unit test: story file without Scope section triggers validation error
- Error message format: "Story {STORY_ID} missing required 'Scope' section. Please add Scope to {file_path}."

### AC13: Temp File Cleanup on Failure
**Given** the elaboration writer or file writer encounters an error
**When** the error occurs (e.g., LLM timeout, write permission denied)
**Then** any temporary files created are cleaned up automatically
**And** no orphaned temp files are left in the filesystem

**Validation:**
- Error handling test: LLM failure leaves no temp files in output directory
- Error handling test: file write failure cleans up temp file before throwing error
- Use Node.js `fs.mkdtemp` with cleanup in error handler or use temp library with auto-cleanup

### AC14: MCP Integration Pathway
**Given** the codebase explorer needs to read files
**When** the MCP adapter (wrkf-1120) is not available
**Then** the codebase explorer falls back to direct filesystem access (Node.js `fs` module)
**And** a clear code comment documents how to swap to MCP adapter when available
**And** the fallback behavior is logged at DEBUG level: "Using direct filesystem access (MCP not available)"

**Validation:**
- Code review confirms fallback implementation exists
- Code comment documents MCP swap: "TODO: Replace with MCP adapter when wrkf-1120 available"
- Integration test with direct filesystem access succeeds

### AC15: Context Extraction Strategy Documentation
**Given** the codebase explorer reads files
**When** extracting context from TypeScript files
**Then** the extraction logic is documented in code comments:
- v1: raw file contents (no AST parsing)
- Future: AST parsing for type extraction (labeled as TODO)
**And** a code comment explains the extraction strategy and future improvements

**Validation:**
- Code review confirms extraction strategy is documented
- Code comment format:
  ```typescript
  // Context Extraction Strategy (v1):
  // - Read raw file contents (no AST parsing)
  // - Include: imports, type definitions, function signatures
  // - TODO: Add AST parsing in v2 for more precise type extraction
  ```

## Reuse Plan

### Existing Components to Reuse

**From wrkf-1010 (GraphState Schema):**
- Base GraphState Zod schema and type inference
- State validation utilities

**From wrkf-1020 (Node Runner Infrastructure):**
- Node factory pattern (`createNode()`)
- Error handling and retry logic
- Logging integration (`@repo/logger`)

**From wrkf-1041 (pm_generate_graph - reference implementation):**
- LLM client wrapper (Claude API integration with retry logic)
- File I/O utilities (read/write with atomic writes)
- Markdown parser utilities (parse sections, extract frontmatter)
- YAML frontmatter parser (validate and extract frontmatter)
- Graph composition patterns (how to define LangGraph edges and nodes)
- Test structure (unit + integration tests for subgraph)

**From monorepo:**
- `@repo/logger` for consistent logging
- Zod for schema validation (already in orchestrator dependencies)
- Existing Turborepo build pipeline

### New Components to Create

**Elaboration Template:**
- `packages/backend/orchestrator/templates/elaboration-template.md` - Markdown template defining elaboration structure

**Codebase Explorer Node:**
- `packages/backend/orchestrator/src/subgraphs/elab-graph/nodes/codebase-explorer.ts` - Novel node to gather codebase context
  - File discovery logic (glob patterns, directory filtering)
  - Context extraction (read file contents, extract types)
  - Context size management (limits, truncation)
  - Performance optimization (timeout, file size limits)
  - Minimum context validation

**AC Validator Node:**
- `packages/backend/orchestrator/src/subgraphs/elab-graph/nodes/ac-validator.ts` - Novel node to validate AC coverage
  - AC extraction from story
  - Coverage analysis (keyword matching, section headers)
  - Coverage report generation

**Elaboration Writer Prompt:**
- `packages/backend/orchestrator/src/subgraphs/elab-graph/prompts/elaboration-writer-prompt.ts` - Prompt template for elaboration generation

## Architecture Notes

### Ports & Adapters Alignment

**Ports (Interfaces):**
- **Story Elaboration Port**: Abstract interface for elaboration generation subgraph
  - Input: Story ID, feature directory
  - Output: Generated elaboration content, validation results, quality metrics

**Adapters (Implementations):**
- **LangGraph Adapter**: Implementation using LangGraphJS for node orchestration
- **Filesystem Adapter**: Read story files, write elaboration files
- **Codebase Adapter**: Read monorepo packages for context (direct filesystem in MVP, MCP in future)
- **LLM Adapter**: Claude API client for elaboration writer node

**Domain Logic (Core):**
- Elaboration validation rules (required sections, AC coverage)
- Context extraction logic (file filtering, type extraction)
- Elaboration structure definition (template)
- Quality metrics computation

**Flow:**
```
CLI Command → Story Elaboration Port → LangGraph Adapter → Nodes (Story Reader → Codebase Explorer → Elaboration Writer → AC Validator) → Filesystem Adapter → Elaboration File
```

This architecture ensures the subgraph is testable (mock adapters for tests) and extensible (swap LangGraph for alternative orchestration if needed, swap filesystem for MCP adapter).

### Node Execution Flow

```
START
  ↓
Story Reader Node
  - Read story file from filesystem
  - Parse YAML frontmatter and markdown sections
  - Validate required sections (fail if "Scope" missing)
  - Extract: title, context, goal, scope, acceptance criteria
  - Add story content to GraphState
  ↓
Codebase Explorer Node
  - Read packages listed in story scope
  - Filter files (src/**/*.ts, skip dist/, node_modules/)
  - Extract context (file paths, type definitions, test patterns)
  - Apply context size limits (max 100KB)
  - Validate minimum context (3 packages OR 5 files)
  - Add codebase context to GraphState
  ↓
Elaboration Writer Node (LLM)
  - Construct prompt from story content + codebase context + template
  - Call Claude API to generate elaboration content
  - Extract token counts from API response
  - Add generated content and LLM metrics to GraphState
  - Retry on transient errors (up to 3 times)
  ↓
AC Validator Node
  - Parse generated elaboration
  - Extract acceptance criteria from story
  - Check each AC for coverage in elaboration (keyword matching)
  - Compute quality metrics (sections count, AC coverage %, context size, latency)
  - Add validation results and quality metrics to GraphState
  - If invalid (missing AC coverage) → ERROR state
  ↓
File Writer (part of AC Validator or separate node)
  - Write elaboration to output path (atomic write with temp file)
  - Clean up temp file on error
  - If write fails → ERROR state
  ↓
END (SUCCESS or ERROR)
```

### GraphState Schema Extension

```typescript
// Extension to base GraphState from wrkf-1010
const ElaborationStateSchema = z.object({
  storyContent: z.object({
    title: z.string(),
    context: z.string(),
    goal: z.string(),
    scope: z.string(),
    acceptanceCriteria: z.array(z.string()),
  }).optional(),

  codebaseContext: z.object({
    filePaths: z.array(z.string()),
    typeDefinitions: z.string(),
    testPatterns: z.string(),
  }).optional(),

  generatedElaborationContent: z.string().optional(),

  validationResults: z.object({
    isValid: z.boolean(),
    coveredACs: z.array(z.string()),
    missingACs: z.array(z.string()),
    coveragePercentage: z.number(),
  }).optional(),

  metrics: z.object({
    llmUsage: z.object({
      inputTokens: z.number(),
      outputTokens: z.number(),
      totalTokens: z.number(),
      model: z.string(),
    }),
  }).optional(),

  qualityMetrics: z.object({
    sectionsCount: z.number(),
    acCoveragePercentage: z.number(),
    contextSizeBytes: z.number(),
    llmLatencyMs: z.number(),
    generatedAt: z.string(), // ISO 8601
  }).optional(),
})

// Merged with base GraphState
type ExtendedGraphState = z.infer<typeof GraphStateSchema> & z.infer<typeof ElaborationStateSchema>
```

## Infrastructure Notes

### Dependencies

**Required:**
- LangGraphJS (already in orchestrator package)
- Anthropic SDK (`@anthropic-ai/sdk`) for Claude API access
- Zod for schema validation (already in orchestrator)
- `@repo/logger` for logging

**Optional:**
- MCP adapter (if wrkf-1120 completed) for codebase exploration
- Otherwise, use direct filesystem access

### Environment Variables

**Required:**
- `ANTHROPIC_API_KEY` - Claude API key for elaboration writer node

**Optional:**
- `ELABORATION_TEMPLATE_PATH` - Override default template location (defaults to `packages/backend/orchestrator/templates/elaboration-template.md`)
- `CODEBASE_CONTEXT_LIMIT` - Override context size limit (defaults to 100KB)
- `LOG_LEVEL` - Logging verbosity (DEBUG, INFO, ERROR)

### Runtime Considerations

**Performance:**
- End-to-end graph execution time: ~30-60 seconds (depends on codebase exploration + LLM latency)
- Codebase exploration: ~10-20 seconds for typical package scope
- LLM call duration: ~10-30 seconds per elaboration (Claude Sonnet 4.5)
- Context size: limited to 100KB to manage LLM context window and costs

**Concurrency:**
- File write operations must be atomic (write to temp, rename) to prevent corruption
- Temp file cleanup required in error handling

**Error Recovery:**
- LLM failures retry up to 3 times with exponential backoff
- File I/O errors fail immediately (no retry) with clear error messages
- Codebase explorer errors (file unreadable) log warning and continue with partial context
- Validation failures halt graph with actionable error details

## HTTP Contract Plan

**Not applicable** - This is backend infrastructure, not an HTTP API.

The subgraph is invoked via CLI command (`/elab-story`), not via HTTP endpoints.

## Seed Requirements

**Not applicable** - No database seeding required.

Elaboration generation reads from filesystem (story, codebase) and writes to filesystem (elaboration file). No database state involved.

## Test Plan

### Scope Summary

**Endpoints touched:** None (backend infrastructure)
**UI touched:** No
**Data/storage touched:** No (filesystem I/O only)

**Components affected:**
- `packages/backend/orchestrator/src/subgraphs/elab-graph/`
- Story elaboration nodes (story reader, codebase explorer, elaboration writer, AC validator)
- LangGraph state management for elaboration workflow

### Happy Path Tests

#### Test 1: Generate Elaboration from Valid Story File
**Setup:**
- Valid story file exists at `{FEATURE_DIR}/{STORY_ID}/{STORY_ID}.md`
- Story contains all required sections (Context, Goal, Scope, Acceptance Criteria)
- Output directory exists

**Action:**
- Invoke `elab_graph` subgraph with story ID
- Graph executes: story reader → codebase explorer → elaboration writer → AC validator

**Expected outcome:**
- Elaboration file created at `{FEATURE_DIR}/{STORY_ID}/ELAB-{STORY_ID}.md`
- Elaboration contains all required sections (Scope, Implementation Plan, Technical Approach, AC Breakdown)
- No validation errors
- GraphState contains metrics (LLM usage, quality metrics)

**Evidence:**
- Elaboration file exists at expected path
- All required sections present in elaboration
- Log shows successful node execution sequence
- GraphState inspection confirms metrics populated

#### Test 2: LLM Cost Tracking
**Setup:**
- Story reader and codebase explorer have populated GraphState

**Action:**
- Execute elaboration writer node with mocked Claude API that returns token counts

**Expected outcome:**
- Token counts extracted from API response
- GraphState contains `metrics.llmUsage` with inputTokens, outputTokens, totalTokens
- Log shows token counts

**Evidence:**
- GraphState inspection shows token metrics
- Log contains: "Elaboration generation: input_tokens=X, output_tokens=Y"

#### Test 3: Quality Metrics Captured
**Setup:**
- Elaboration writer produces complete elaboration

**Action:**
- Execute AC validator node

**Expected outcome:**
- GraphState contains `qualityMetrics` with sectionsCount, acCoveragePercentage, contextSizeBytes, llmLatencyMs, generatedAt
- All metrics are non-zero and valid

**Evidence:**
- GraphState inspection shows quality metrics
- Sections count matches elaboration structure
- AC coverage percentage is 100%

#### Test 4: Minimum Context Requirements Met
**Setup:**
- Story scope includes 3 packages with accessible files

**Action:**
- Execute codebase explorer node

**Expected outcome:**
- Context gathering succeeds
- No minimum context error

**Evidence:**
- Log shows "Context requirements met: 3 packages, X files"
- Graph continues to elaboration writer

### Error Cases

#### Error 1: Story Missing Scope Section
**Setup:** Story file exists but missing "Scope" section
**Action:** Execute story reader node
**Expected:** Story reader fails with "Story missing required 'Scope' section" error
**Evidence:** Error logged, GraphState contains error with actionable message

#### Error 2: Insufficient Context (Minimum Requirements Not Met)
**Setup:** Story scope references only 1 package with 2 files
**Action:** Execute codebase explorer node
**Expected:** Graph fails with "Insufficient context: Found 1 packages, 2 files. Required: 3 packages OR 5 files."
**Evidence:** Error logged with counts, graph halts

#### Error 3: LLM Failure with Temp File Cleanup
**Setup:** Elaboration writer encounters LLM API error
**Action:** Execute elaboration writer with mocked LLM error
**Expected:** Graph fails gracefully, no temp files left in output directory
**Evidence:** Error logged, output directory is clean (no orphaned temp files)

### Required Tooling Evidence

**Backend (LangGraph Orchestrator):**

**Required test execution:**
- Unit tests for each node (story reader, codebase explorer, elaboration writer, AC validator)
- Integration test for full `elab_graph` execution
- Error handling tests for each error case

**Assertions:**
- Node execution order: story reader → codebase explorer → elaboration writer → AC validator
- GraphState transitions correctly through nodes
- File I/O operations succeed (read story, write elaboration)
- LLM cost tracking captures token counts
- Quality metrics populated in GraphState
- Minimum context validation works
- Temp file cleanup on error
- Error states propagate correctly in GraphState

**Test framework:**
- Vitest for unit and integration tests
- Mocked filesystem for file I/O tests
- Mocked LLM client for elaboration writer tests (deterministic responses)
- Real filesystem in E2E tests (use temp directories and test fixtures)

**Evidence artifacts:**
- Test coverage report (>45% minimum, aim for >80% on new code)
- Sample elaboration outputs from test runs
- Error case logs showing proper error handling
- GraphState snapshots at each node transition with metrics
- Codebase explorer context samples (show what files/types were gathered)

## UI/UX Notes

**Not applicable** - This story implements backend infrastructure (LangGraph subgraph) with no UI components.

---

## Implementation Checklist (For Dev)

Before creating PR:
- [ ] All unit tests pass locally (`pnpm test`)
- [ ] Integration test passes locally (full graph execution)
- [ ] Lint and type-check pass (`pnpm lint`, `pnpm check-types`)
- [ ] Sample elaboration output committed to `_pm/sample-elaboration.md`
- [ ] GraphState schema changes documented in commit message
- [ ] Elaboration template committed to `templates/elaboration-template.md`
- [ ] README or inline comments explain node responsibilities
- [ ] Error messages are actionable (no generic "Error occurred" messages)
- [ ] Retry logic tested with LLM mock failures
- [ ] File I/O atomic writes tested (no partial files on error)
- [ ] Temp file cleanup tested in error scenarios
- [ ] Codebase explorer context size limits tested
- [ ] Minimum context validation tested
- [ ] AC validator coverage tests pass (detect missing ACs)
- [ ] LLM cost tracking verified in integration test
- [ ] Quality metrics verified in integration test
