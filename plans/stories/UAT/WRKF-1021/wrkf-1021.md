---
status: uat
follow_up_from: wrkf-1020
---

# wrkf-1021: Node Execution Metrics

## Follow-up Context

This story is a follow-up from wrkf-1020 identified during QA Elaboration.

- **Parent Story:** wrkf-1020 (Node Runner Infrastructure)
- **Source:** QA Discovery Notes
- **Original Finding:** Node execution metrics/telemetry — Add structured metrics capture (execution counts, success/failure rates, duration percentiles) similar to @repo/api-client RetryMetrics
- **Category:** Enhancement Opportunity
- **Impact:** Medium
- **Effort:** Medium

---

## Context

The Node Runner Infrastructure (wrkf-1020) provides logging for node entry/exit with execution duration. However, for production observability and debugging, aggregated metrics are needed to understand node behavior over time.

The `@repo/api-client` package has a proven `RetryMetrics` pattern that captures:
- Total execution counts
- Success/failure rates
- Retry attempt distribution
- Duration percentiles

This pattern should be adapted for the orchestrator to provide similar observability for graph node execution.

---

## Goal

Add structured metrics capture to the Node Runner Infrastructure, enabling observability of node execution patterns including success rates, failure rates, retry distributions, and execution duration percentiles.

---

## Non-Goals

- **NOT** re-implementing the node factory or retry logic (that is wrkf-1020's scope)
- **NOT** implementing external metrics export (Prometheus, CloudWatch, etc.)
- **NOT** implementing dashboards or alerting
- **NOT** implementing distributed tracing

---

## Scope

### Endpoints and Surfaces

**None.** This is a pure TypeScript library extension with no API endpoints.

### Packages/Apps Affected

| Package/App | Change Type |
|-------------|-------------|
| `packages/backend/orchestrator` | MODIFY — Add `src/runner/metrics.ts` module |
| `packages/backend/orchestrator` | MODIFY — Integrate metrics capture into node factory |

---

## Acceptance Criteria

- [ ] **AC-1:** `NodeMetrics` Zod schema captures per-node metrics: `totalExecutions`, `successCount`, `failureCount`, `retryCount`, `lastExecutionMs`, `avgExecutionMs`
- [ ] **AC-2:** `NodeMetricsCollector` class provides methods: `recordSuccess(nodeName, durationMs)`, `recordFailure(nodeName, durationMs, error)`, `recordRetry(nodeName, attemptNumber)`
- [ ] **AC-3:** `getNodeMetrics(nodeName): NodeMetrics` returns current metrics for a specific node
- [ ] **AC-4:** `getAllNodeMetrics(): Map<string, NodeMetrics>` returns metrics for all nodes
- [ ] **AC-5:** `resetNodeMetrics(nodeName?)` clears metrics for a specific node or all nodes
- [ ] **AC-6:** Node factory (`createNode()`) automatically records metrics when `metricsCollector` is provided in config
- [ ] **AC-7:** Metrics capture is optional — nodes work without metrics collector configured
- [ ] **AC-8:** Metrics include duration percentiles: p50, p90, p99 (calculated from rolling window)
- [ ] **AC-9:** All exports importable from `@repo/orchestrator`:
  ```typescript
  import {
    NodeMetrics,
    NodeMetricsCollector,
    createNodeMetricsCollector,
  } from '@repo/orchestrator'
  ```
- [ ] **AC-10:** Unit tests cover metrics recording, retrieval, and reset with **80%+ coverage**
- [ ] **AC-11:** Integration test verifies metrics are captured during actual node execution
- [ ] **AC-12:** `NodeMetricsCollector` accepts optional `windowSize` parameter (default: 100) controlling the rolling window for percentile calculations
- [ ] **AC-13:** Metric recording methods are safe for concurrent async calls. Simple counter increments are atomic; duration percentile updates maintain consistency during interleaved async operations
- [ ] **AC-14:** `recordSuccess()` and `recordFailure()` validate `durationMs` input. Negative values are clamped to 0 with a warning logged via `@repo/logger`
- [ ] **AC-15:** `NodeMetrics` tracks failure counts by error category: `timeoutErrors`, `validationErrors`, `networkErrors`, `otherErrors`. `recordFailure()` accepts optional `errorType` parameter
- [ ] **AC-16:** `NodeMetricsCollector.toJSON(): SerializedMetrics` returns a JSON-serializable snapshot of all node metrics for external consumption
- [ ] **AC-17:** `NodeMetricsCollector` supports optional threshold configuration and emits events when thresholds are breached: `onFailureRateThreshold(nodeName, rate)` when failure rate exceeds configured threshold, `onLatencyThreshold(nodeName, p99)` when p99 latency exceeds configured threshold

---

## Reuse Plan

### Existing Packages to Reuse

| Package | Usage |
|---------|-------|
| `@repo/api-client` | Reference RetryMetrics pattern for design |
| `zod` | Schema definitions |
| `@repo/logger` | Metrics logging (optional debug output) |

### Patterns to Adapt

The `RetryMetrics` class in `@repo/api-client` provides the pattern:
- Counter-based metrics (success, failure, retry counts)
- Duration tracking with percentiles
- Reset capability

Adapt for node execution context (node names instead of request URLs).

### New Shared Code Created

| Export | Purpose | Consumers |
|--------|---------|-----------|
| `NodeMetrics` | Type for node metrics data | Dashboard tools, debugging |
| `NodeMetricsCollector` | Collector class | Node factory, graph runtime |
| `createNodeMetricsCollector()` | Factory function | Graph initialization |

---

## Architecture Notes (Ports & Adapters)

### Package Structure Addition

```
packages/backend/orchestrator/src/runner/
├── metrics.ts                    # CREATE — NodeMetricsCollector
├── __tests__/
│   └── metrics.test.ts           # CREATE — metrics tests
```

### Integration Point

The `createNode()` factory accepts an optional `metricsCollector` in its config:

```typescript
const node = createNode({
  name: 'my-node',
  metricsCollector: collector, // optional
}, async (state) => { ... })
```

When provided, the factory wrapper automatically calls:
- `collector.recordSuccess()` on successful execution
- `collector.recordFailure()` on error
- `collector.recordRetry()` on retry attempts

---

## Test Plan

### Happy Path Tests

| ID | Test Description | Expected Outcome |
|----|------------------|------------------|
| HP-1 | Create metrics collector | Collector instance created |
| HP-2 | Record successful node execution | successCount increments, duration recorded |
| HP-3 | Record failed node execution | failureCount increments, error tracked |
| HP-4 | Record retry attempt | retryCount increments |
| HP-5 | Get metrics for specific node | Returns NodeMetrics for that node |
| HP-6 | Get all node metrics | Returns Map of all nodes |
| HP-7 | Calculate duration percentiles | p50, p90, p99 calculated correctly |
| HP-8 | Node factory integrates with collector | Metrics recorded automatically |
| HP-9 | Create collector with custom windowSize | Collector uses custom window size |
| HP-10 | Record failure with error category | Category counters (timeoutErrors, etc.) increment correctly |
| HP-11 | Call toJSON() | Returns JSON-serializable snapshot of all metrics |
| HP-12 | Configure failure rate threshold and exceed it | onFailureRateThreshold callback invoked with nodeName and rate |
| HP-13 | Configure latency threshold and exceed it | onLatencyThreshold callback invoked with nodeName and p99 |

### Error Cases

| ID | Test Description | Expected Error |
|----|------------------|----------------|
| EC-1 | Get metrics for unknown node | Returns empty/default metrics |
| EC-2 | Reset metrics for unknown node | No-op, no error |

### Edge Cases

| ID | Test Description | Expected Behavior |
|----|------------------|-------------------|
| EDGE-1 | Percentiles with single data point | p50=p90=p99=that value |
| EDGE-2 | Node with no executions | All counts zero, no percentiles |
| EDGE-3 | Concurrent metric recording | Thread-safe updates (AC-13) |
| EDGE-4 | Very large duration values | Handled without overflow |
| EDGE-5 | Negative durationMs value | Clamped to 0, warning logged via @repo/logger (AC-14) |
| EDGE-6 | Rolling window exceeds windowSize | Oldest samples evicted, percentiles remain accurate |
| EDGE-7 | Threshold callback not configured | No error when threshold exceeded |
| EDGE-8 | Multiple concurrent async metric recordings | All recordings complete without data loss (AC-13) |

---

## Risks / Edge Cases

| Risk | Mitigation |
|------|------------|
| Memory growth with many nodes | Rolling window for percentiles, optional reset |
| Performance overhead | Minimal — simple counter increments |
| Percentile calculation accuracy | Use standard algorithm (sorted insertion or streaming) |

---

## Open Questions

None — design follows established RetryMetrics pattern.

---

## File Touch List

| Path | Action |
|------|--------|
| `packages/backend/orchestrator/src/runner/metrics.ts` | CREATE |
| `packages/backend/orchestrator/src/runner/__tests__/metrics.test.ts` | CREATE |
| `packages/backend/orchestrator/src/runner/node-factory.ts` | MODIFY — add metricsCollector support |
| `packages/backend/orchestrator/src/runner/index.ts` | MODIFY — export metrics |
| `packages/backend/orchestrator/src/index.ts` | MODIFY — re-export metrics |

---

## Token Budget

| Phase | Agent | Est. Tokens | Actual Tokens |
|-------|-------|-------------|---------------|
| Generation | PM | ~3,000 | — |
| Elaboration | QA | ~2,000 | ~103,279 |
| Implementation | Dev | ~8,000 | — |
| Verification | QA | ~2,000 | — |

_Note: Elaboration tokens include four rounds: initial (~23,101 input + ~2,000 output), second (~21,221 input + ~1,875 output), third (~25,846 input + ~2,375 output), and fourth (~24,736 input + ~2,125 output) elaborations. Higher than estimate due to interactive discovery, comprehensive reference file reads, and re-elaborations pending PM fix. Implementation estimate increased to account for 6 additional ACs. Final verdict: PASS._

---

*Generated by PM Agent | 2026-01-24*
*Follow-up from wrkf-1020 QA Elaboration*

---

## QA Discovery Notes (for PM Review)

_Added by QA Elaboration on 2026-01-24_

### Gaps Identified

| # | Finding | User Decision | Notes |
|---|---------|---------------|-------|
| 1 | Thread safety for concurrent async metric recording | Added as AC | Need atomic update guidance for JS async patterns |
| 2 | Negative duration handling (clock skew) | Added as AC | Clamp to 0 with warning log |
| 3 | Rolling window size not configurable | Added as AC | Default 100 samples, optional config |

### Enhancement Opportunities

| # | Finding | User Decision | Notes |
|---|---------|---------------|-------|
| 1 | Histogram bucketing for percentiles | Skipped | Not needed for current scope |
| 2 | Sliding time window (last N minutes) | Skipped | Not needed for current scope |
| 3 | Error type breakdown in failure tracking | Added as AC | Track by error category |
| 4 | Snapshot/export method (toJSON) | Added as AC | Enable external consumption |
| 5 | Event emitter for threshold breaches | Added as AC | Enable reactive alerting |

### New Acceptance Criteria (from QA Elaboration)

_AC-12 through AC-17 have been moved to the main Acceptance Criteria section above._

### Follow-up Stories Suggested

- None — all identified enhancements were either added to this story or explicitly skipped.

### Items Marked Out-of-Scope

- Histogram bucketing — Not needed for current observability requirements
- Sliding time window — Over-engineering for initial implementation

---

## PM Fix Log

_Fixed by PM Agent | 2026-01-24_

### Issue Resolved

**ELAB-WRKF-1021 Issue #1 (High Severity):** AC-12 through AC-17 were documented in "QA Discovery Notes" but not in the main "Acceptance Criteria" section.

### Changes Made

1. **Moved AC-12 through AC-17 to main Acceptance Criteria section** — All 6 ACs are now in the proper location for implementation tracking
2. **Updated Test Plan** — Added HP-9 through HP-13 (happy path tests) and EDGE-5 through EDGE-8 (edge case tests) to cover the new ACs
3. **Updated status** — Changed from `needs-refinement` to `backlog`

### Next Step

Run QA Audit again: `/qa-audit-story wrkf-1021`
