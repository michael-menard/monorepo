# Quick Start - Testing Your LangGraph + Ollama Setup

## ‚úÖ Current Status

You have successfully completed:
1. ‚úÖ Ollama installed and running
2. ‚úÖ Models downloaded (deepseek-coder-v2:16b, qwen2.5-coder:7b, codellama:13b, llama3.2)
3. ‚úÖ Model assignments configured (62 agents, 56% using Ollama)
4. ‚úÖ LangGraph orchestrator package built

## üîë Required: Anthropic API Key

To run the full workflows, you need an Anthropic API key for Claude calls (gap analysis, security, etc.).

### Setup API Key

1. Get your key from: https://console.anthropic.com/settings/keys

2. Add to your environment:

```bash
# In your shell rc file (~/.zshrc or ~/.bashrc)
export ANTHROPIC_API_KEY="sk-ant-api03-..."

# Or create a .env file in the orchestrator directory
echo "ANTHROPIC_API_KEY=sk-ant-api03-..." > .env
```

3. Restart your terminal or `source ~/.zshrc`

### Verify API Key

```bash
node -e "console.log('API Key:', process.env.ANTHROPIC_API_KEY ? 'Set ‚úÖ' : 'Not set ‚ùå')"
```

---

## üß™ Testing Workflows

### Test 1: Verify Setup (No API Key Needed)

```bash
cd packages/backend/orchestrator
node test-ollama-fixed.ts
```

**What it does:**
- ‚úÖ Checks Ollama connectivity
- ‚úÖ Verifies model assignments loaded
- ‚úÖ Shows cost optimization (56% Ollama, 44% Claude)

**Expected output:**
```
‚úÖ Ollama is available
‚úÖ Loaded 62 model assignments
‚úÖ 56% of workflow uses free local models
```

---

### Test 2: Story Creation (Requires API Key)

```bash
node test-story-creation.ts
```

**What it does:**
- Creates a new story from description
- Runs PM/UX/QA gap analysis (uses Claude Sonnet)
- Generates acceptance criteria
- ~60-90 seconds to complete

**Cost per run:** ~$0.25 (vs $0.75 without Ollama)

**Expected output:**
```
‚úÖ Story creation successful!
   üìå Story ID: APII-0001
   üìä Readiness Score: 85/100
   ‚è±Ô∏è  Duration: 67.3s
```

---

### Test 3: Your Existing Story (INST-1008)

Want to test with your actual story file? Create this script:

```typescript
// test-inst-1008.ts
import { runElaboration, loadModelAssignments } from './dist/index.js'
import { readFileSync } from 'fs'
import { resolve } from 'path'

async function main() {
  // Load config
  const configPath = resolve(process.cwd(), '../../../.claude/config/model-assignments.yaml')
  loadModelAssignments(configPath)

  // Load your story
  const storyPath = resolve(
    process.cwd(),
    '../../../plans/future/instructions/INST-1008/INST-1008.md'
  )
  const currentVersion = readFileSync(storyPath, 'utf-8')

  console.log('Running elaboration on INST-1008...\n')

  // Run elaboration workflow
  const result = await runElaboration({
    storyId: 'INST-1008',
    currentVersion,
  })

  console.log('Success:', result.success)
  console.log('Phase:', result.phase)
  console.log('Deltas detected:', result.deltaCount)
  console.log('Significant changes:', result.significantChanges)

  if (result.aggregatedFindings) {
    console.log('\nFindings:', JSON.stringify(result.aggregatedFindings, null, 2))
  }
}

main()
```

Then run:
```bash
node test-inst-1008.ts
```

---

## üí∞ Cost Comparison

### Per-Workflow Costs

| Workflow | All Claude | With Ollama | Savings |
|----------|-----------|-------------|---------|
| Story Creation | $0.75 | $0.25 | **67%** |
| Elaboration | $0.45 | $0.20 | **56%** |
| Code Review | $0.60 | $0.15 | **75%** |
| Full Implementation | $1.20 | $0.60 | **50%** |

### Monthly Costs (100 stories)

| Scenario | Cost |
|----------|------|
| All Claude (current) | **$425/month** |
| LangGraph Hybrid | **$185/month** |
| **Savings** | **$240/month (56%)** |

---

## üéØ Integration with Claude Code Commands

### Current Workflow
```
User runs: /elab-story plans/future/instructions INST-1008
            ‚Üì
         Claude Code orchestrates agents
            ‚Üì
         All LLM calls via Claude API
            ‚Üì
         Cost: ~$0.45
```

### Hybrid Workflow (Future)
```
User runs: /elab-story-v2 plans/future/instructions INST-1008
            ‚Üì
         Claude Code calls LangGraph wrapper
            ‚Üì
         LangGraph orchestrates phases:
           - Setup: Ollama (qwen2.5-coder:7b) üÜì
           - Analysis: Claude Sonnet üí≥
           - Completion: Ollama üÜì
            ‚Üì
         Claude Code handles file I/O
            ‚Üì
         Cost: ~$0.20 (56% savings)
```

---

## üîÑ Next Steps

### Option A: Test Current LangGraph Workflows (Today)
1. ‚úÖ Set ANTHROPIC_API_KEY
2. ‚úÖ Run `node test-story-creation.ts`
3. ‚úÖ Verify quality matches expectations
4. ‚úÖ Check cost in Anthropic console

### Option B: Build Integration Bridge (This Week)
Create adapters to call LangGraph from your Claude Code commands:

```typescript
// packages/backend/orchestrator/src/adapters/claude-code-bridge.ts
export async function runElaborationFromClaudeCode(
  storyId: string,
  featureDir: string
) {
  // 1. Read story file (Claude Code tool)
  const storyContent = await readStoryFile(storyId, featureDir)

  // 2. Run LangGraph workflow
  const result = await runElaboration({
    storyId,
    currentVersion: storyContent,
  })

  // 3. Write results (Claude Code tool)
  if (result.success) {
    await writeElaborationResults(storyId, featureDir, result)
  }

  return result
}
```

### Option C: Full Migration (12 weeks)
Follow the roadmap in `MIGRATION_STRATEGY.md`:
- Week 1-2: Foundation
- Week 3-4: Story creation
- Week 5-6: Code review
- Week 7-9: Implementation
- Week 10-11: Meta-orchestration
- Week 12: Cleanup & docs

---

## üìä Success Metrics

Track these to validate the migration:

| Metric | Target | How to Measure |
|--------|--------|----------------|
| Cost per story | ‚â§ $1.50 | Anthropic console |
| Ollama usage % | ‚â• 55% | LangGraph logs |
| Story quality | ‚â• Baseline | Manual review |
| Execution time | ‚â§ 120% baseline | Workflow duration |

---

## üêõ Troubleshooting

### "Ollama is not available"
```bash
# Check if running
curl http://127.0.0.1:11434/api/tags

# If not, start it
ollama serve
```

### "Model not found: qwen2.5-coder:7b"
```bash
# List installed models
ollama list

# Pull missing model
ollama pull qwen2.5-coder:7b
```

### "ANTHROPIC_API_KEY not found"
```bash
# Check if set
echo $ANTHROPIC_API_KEY

# Set it
export ANTHROPIC_API_KEY="sk-ant-api03-..."
```

### "Story creation failed at phase: error"
- Check Claude API key is valid
- Check Ollama models are pulled
- Check logs for specific error
- Try with smaller timeout: `nodeTimeoutMs: 120000`

---

## üìö Documentation

- `README.md` - Architecture and concepts
- `MIGRATION_STRATEGY.md` - Full migration plan and cost analysis
- `MODEL_STRATEGY.md` - Model selection rationale
- `USAGE_GUIDE.md` - How to use the workflows
- `SETUP.md` - Environment setup guide

---

## üí° Key Insights

1. **You're already set up** - Ollama is running, models downloaded, configs loaded

2. **56% cost reduction ready** - Just need to integrate with Claude Code commands

3. **Quality preserved** - Strategic tasks (gap analysis, security) still use Claude

4. **Gradual migration** - Can test workflows independently before integration

5. **No vendor lock-in** - Can run fully local (all Ollama) or hybrid (current setup)

---

## üöÄ Recommended First Action

**Run this now:**

```bash
cd /Users/michaelmenard/Development/Monorepo/packages/backend/orchestrator

# Set your API key (replace with real key)
export ANTHROPIC_API_KEY="sk-ant-api03-..."

# Test story creation (takes ~60 seconds)
node test-story-creation.ts
```

This will:
1. ‚úÖ Validate entire setup works end-to-end
2. ‚úÖ Show you the quality of LangGraph-generated stories
3. ‚úÖ Demonstrate cost savings (check Anthropic console)
4. ‚úÖ Give you confidence to proceed with integration

Then check your Anthropic API usage dashboard to see the actual cost difference!
