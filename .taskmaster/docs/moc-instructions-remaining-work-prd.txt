# MOC Instructions Backend - Remaining Implementation PRD

## Overview
Complete the backend implementation of the MOC Instructions Library feature. The database schema, S3 utilities, and Elasticsearch setup are complete. Focus on implementing the remaining API endpoints, access control, and comprehensive testing.

## Current Status
✅ Completed:
- PostgreSQL schema for MOC metadata and file references
- S3 file upload utility (user-scoped)
- S3 file download and deletion utility
- Elasticsearch index setup for MOC metadata

❌ Remaining Work:
- API endpoint implementations
- Access control enforcement
- File validation logic
- Comprehensive testing
- Error handling and edge cases

## Core Requirements

### 1. API Endpoints Implementation
- POST /api/mocs: Create new MOC with metadata
- PATCH /api/mocs/:id: Update MOC metadata
- POST /api/mocs/:id/files: Upload instruction or parts list file
- DELETE /api/mocs/:id/files/:fileId: Delete file
- GET /api/mocs/search: Full-text search via Elasticsearch

### 2. Access Control & Security
- Enforce that only owners/admins can view/edit/delete MOCs
- Return 403 Forbidden for unauthorized access
- Validate user ownership on all operations

### 3. File Management
- Validate file types (PDF, .io for instructions; CSV, JSON for parts lists)
- Enforce single instruction file per MOC
- Handle file deletion and missing file edge cases
- Gracefully handle S3 corruption scenarios

### 4. Data Validation
- Input validation using Zod schemas
- File type validation
- Metadata validation (title, description, tags)
- User ownership validation

### 5. Error Handling
- Handle Elasticsearch downtime gracefully
- Handle S3 upload/download failures
- Handle database connection issues
- Provide meaningful error messages

### 6. Testing
- Jest + Supertest tests for all endpoints
- Test success and error cases
- Test file upload/download edge cases
- Test permission checks
- Mock all external dependencies

## Technical Specifications

### Database Operations
- Use existing PostgreSQL schema
- Implement proper transaction handling
- Handle concurrent access scenarios

### File Storage
- Use existing S3 utilities
- Implement proper file cleanup on deletion
- Handle file size limits and validation

### Search Functionality
- Use existing Elasticsearch setup
- Implement full-text search on title, tags, description
- Handle search result pagination

### Response Format
- Use uniform API response format with status code, message, and data
- Include proper HTTP status codes
- Provide detailed error messages for debugging

## Acceptance Criteria

### For Each Endpoint:
- ✅ Returns proper HTTP status codes
- ✅ Validates input data
- ✅ Enforces access control
- ✅ Handles errors gracefully
- ✅ Includes comprehensive tests
- ✅ Uses uniform response format

### For File Operations:
- ✅ Validates file types
- ✅ Enforces single instruction file per MOC
- ✅ Handles upload failures
- ✅ Cleans up on deletion
- ✅ Validates file ownership

### For Search:
- ✅ Returns relevant results
- ✅ Handles Elasticsearch downtime
- ✅ Supports pagination
- ✅ Filters by user ownership

## Priority Order
1. High Priority: Core API endpoints (5, 6, 7, 8)
2. High Priority: Access control enforcement (11)
3. High Priority: File validation (10)
4. High Priority: Comprehensive testing (13)
5. Medium Priority: Search endpoint (9)
6. Medium Priority: Edge case handling (12, 14)
7. Low Priority: Documentation (15)

## Success Metrics
- All endpoints return proper responses
- All tests pass with >90% coverage
- No security vulnerabilities
- Proper error handling for all scenarios
- Performance meets requirements 